{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a7264c0b",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-04-12T08:45:17.149122Z",
     "iopub.status.busy": "2025-04-12T08:45:17.148829Z",
     "iopub.status.idle": "2025-04-12T08:45:17.155430Z",
     "shell.execute_reply": "2025-04-12T08:45:17.154781Z"
    },
    "papermill": {
     "duration": 0.011466,
     "end_time": "2025-04-12T08:45:17.156510",
     "exception": false,
     "start_time": "2025-04-12T08:45:17.145044",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello World\n"
     ]
    }
   ],
   "source": [
    "print(\"Hello World\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "331c32df",
   "metadata": {
    "papermill": {
     "duration": 0.002031,
     "end_time": "2025-04-12T08:45:17.160885",
     "exception": false,
     "start_time": "2025-04-12T08:45:17.158854",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### GEN AI\n",
    "- Question 2 CycleGAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e415ce65",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-12T08:45:17.166543Z",
     "iopub.status.busy": "2025-04-12T08:45:17.166358Z",
     "iopub.status.idle": "2025-04-12T08:54:38.404226Z",
     "shell.execute_reply": "2025-04-12T08:54:38.403374Z"
    },
    "papermill": {
     "duration": 561.242734,
     "end_time": "2025-04-12T08:54:38.405719",
     "exception": false,
     "start_time": "2025-04-12T08:45:17.162985",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "Finding images in dataset...\n",
      "Found 44668 image files\n",
      "\n",
      "Potential face directories: ['/kaggle/input/person-face-sketches/train/sketches', '/kaggle/input/person-face-sketches/test/photos', '/kaggle/input/person-face-sketches/val/sketches', '/kaggle/input/person-face-sketches/val/photos', '/kaggle/input/person-face-sketches/train/photos', '/kaggle/input/person-face-sketches/test/sketches']\n",
      "Potential sketch directories: []\n",
      "\n",
      "Couldn't clearly identify face and sketch images by names. Attempting to split by directories...\n",
      "Using /kaggle/input/person-face-sketches/train/sketches as face directory with 20655 images\n",
      "Using /kaggle/input/person-face-sketches/train/photos as sketch directory with 20655 images\n",
      "\n",
      "Final count: 20655 face images and 20655 sketch images\n",
      "Using 250 matched pairs for training\n",
      "Train dataloader: 225 batches\n",
      "Validation dataloader: 25 batches\n",
      "Generator parameters: 1,965,059\n",
      "Discriminator parameters: 694,241\n",
      "Starting CycleGAN training...\n",
      "[Train] Epoch 1/20 - Batch 10/225, D_face: 0.4540, D_sketch: 0.5866, G: 20.7476, Cycle: 10.2498, Identity: 9.2945\n",
      "[Train] Epoch 1/20 - Batch 20/225, D_face: 0.3405, D_sketch: 0.3198, G: 16.7040, Cycle: 7.1219, Identity: 8.3370\n",
      "[Train] Epoch 1/20 - Batch 30/225, D_face: 0.2297, D_sketch: 0.3994, G: 9.4620, Cycle: 3.8393, Identity: 4.5781\n",
      "[Train] Epoch 1/20 - Batch 40/225, D_face: 0.3429, D_sketch: 0.2520, G: 10.9516, Cycle: 5.0264, Identity: 4.8816\n",
      "[Train] Epoch 1/20 - Batch 50/225, D_face: 0.1583, D_sketch: 0.1473, G: 9.9413, Cycle: 4.0641, Identity: 3.9798\n",
      "[Train] Epoch 1/20 - Batch 60/225, D_face: 0.0976, D_sketch: 0.1304, G: 17.7207, Cycle: 11.0792, Identity: 4.8806\n",
      "[Train] Epoch 1/20 - Batch 70/225, D_face: 0.1812, D_sketch: 0.1138, G: 10.2041, Cycle: 4.3927, Identity: 3.7112\n",
      "[Train] Epoch 1/20 - Batch 80/225, D_face: 0.1466, D_sketch: 0.1897, G: 9.1055, Cycle: 4.2319, Identity: 3.4166\n",
      "[Train] Epoch 1/20 - Batch 90/225, D_face: 0.1526, D_sketch: 0.1143, G: 7.8869, Cycle: 3.8209, Identity: 2.2732\n",
      "[Train] Epoch 1/20 - Batch 100/225, D_face: 0.0452, D_sketch: 0.0679, G: 7.8495, Cycle: 3.0927, Identity: 2.8032\n",
      "[Train] Epoch 1/20 - Batch 110/225, D_face: 0.0673, D_sketch: 0.0932, G: 7.3488, Cycle: 2.9001, Identity: 2.5254\n",
      "[Train] Epoch 1/20 - Batch 120/225, D_face: 0.1600, D_sketch: 0.1447, G: 10.8566, Cycle: 6.6101, Identity: 2.7407\n",
      "[Train] Epoch 1/20 - Batch 130/225, D_face: 0.0467, D_sketch: 0.1000, G: 8.2055, Cycle: 3.9866, Identity: 2.3221\n",
      "[Train] Epoch 1/20 - Batch 140/225, D_face: 0.0469, D_sketch: 0.0852, G: 6.2348, Cycle: 2.7418, Identity: 1.8084\n",
      "[Train] Epoch 1/20 - Batch 150/225, D_face: 0.0370, D_sketch: 0.0418, G: 6.8003, Cycle: 2.8918, Identity: 1.9328\n",
      "[Train] Epoch 1/20 - Batch 160/225, D_face: 0.0557, D_sketch: 0.1727, G: 8.6279, Cycle: 4.6196, Identity: 2.2930\n",
      "[Train] Epoch 1/20 - Batch 170/225, D_face: 0.1201, D_sketch: 0.1239, G: 10.5573, Cycle: 5.6700, Identity: 2.9808\n",
      "[Train] Epoch 1/20 - Batch 180/225, D_face: 0.0475, D_sketch: 0.1854, G: 9.8853, Cycle: 5.2832, Identity: 2.9714\n",
      "[Train] Epoch 1/20 - Batch 190/225, D_face: 0.0340, D_sketch: 0.0766, G: 7.7183, Cycle: 3.5452, Identity: 2.0569\n",
      "[Train] Epoch 1/20 - Batch 200/225, D_face: 0.0244, D_sketch: 0.0510, G: 7.7827, Cycle: 4.2035, Identity: 1.9467\n",
      "[Train] Epoch 1/20 - Batch 210/225, D_face: 0.0288, D_sketch: 0.0642, G: 8.7377, Cycle: 4.6304, Identity: 2.1586\n",
      "[Train] Epoch 1/20 - Batch 220/225, D_face: 0.0408, D_sketch: 0.0359, G: 9.5064, Cycle: 4.7710, Identity: 2.6669\n",
      "[Train] Epoch 1/20 - Batch 225/225, D_face: 0.0535, D_sketch: 0.0644, G: 5.6967, Cycle: 2.2387, Identity: 1.4779\n",
      "[Train] Epoch 1/20, D_face_loss: 0.1378, D_sketch_loss: 0.1783, G_face2sketch_loss: 0.8404, G_sketch2face_loss: 0.9181, cycle_loss: 4.7524, identity_loss: 3.4509, total_G_loss: 9.9619\n",
      "[Validation] Epoch 1/20, D_face_loss: 0.0499, D_sketch_loss: 0.0715, G_face2sketch_loss: 1.2936, G_sketch2face_loss: 0.7962, cycle_loss: 4.1527, identity_loss: 2.2011, total_G_loss: 8.4435\n",
      "Epoch 1 completed in 25.98 seconds\n",
      "[Train] Epoch 2/20 - Batch 10/225, D_face: 0.0240, D_sketch: 0.0417, G: 7.7920, Cycle: 3.6799, Identity: 2.1491\n",
      "[Train] Epoch 2/20 - Batch 20/225, D_face: 0.0351, D_sketch: 0.0379, G: 6.5374, Cycle: 2.9379, Identity: 1.7804\n",
      "[Train] Epoch 2/20 - Batch 30/225, D_face: 0.0263, D_sketch: 0.0422, G: 8.5906, Cycle: 4.3276, Identity: 2.3197\n",
      "[Train] Epoch 2/20 - Batch 40/225, D_face: 0.0146, D_sketch: 0.0660, G: 6.1713, Cycle: 2.3972, Identity: 1.6721\n",
      "[Train] Epoch 2/20 - Batch 50/225, D_face: 0.0132, D_sketch: 0.0318, G: 7.1004, Cycle: 3.0282, Identity: 2.0556\n",
      "[Train] Epoch 2/20 - Batch 60/225, D_face: 0.0149, D_sketch: 0.0593, G: 6.3630, Cycle: 2.9876, Identity: 1.4907\n",
      "[Train] Epoch 2/20 - Batch 70/225, D_face: 0.0179, D_sketch: 0.1064, G: 8.2339, Cycle: 3.6601, Identity: 3.0257\n",
      "[Train] Epoch 2/20 - Batch 80/225, D_face: 0.0255, D_sketch: 0.1514, G: 9.7325, Cycle: 5.5331, Identity: 2.5960\n",
      "[Train] Epoch 2/20 - Batch 90/225, D_face: 0.0398, D_sketch: 0.0293, G: 6.5712, Cycle: 2.3998, Identity: 1.9946\n",
      "[Train] Epoch 2/20 - Batch 100/225, D_face: 0.2818, D_sketch: 0.0348, G: 7.9481, Cycle: 3.7809, Identity: 2.2534\n",
      "[Train] Epoch 2/20 - Batch 110/225, D_face: 0.0194, D_sketch: 0.0369, G: 7.1035, Cycle: 3.2494, Identity: 2.0024\n",
      "[Train] Epoch 2/20 - Batch 120/225, D_face: 0.0153, D_sketch: 0.0552, G: 6.9282, Cycle: 2.9704, Identity: 1.7279\n",
      "[Train] Epoch 2/20 - Batch 130/225, D_face: 0.0215, D_sketch: 0.0163, G: 6.8731, Cycle: 3.0682, Identity: 1.7069\n",
      "[Train] Epoch 2/20 - Batch 140/225, D_face: 0.0186, D_sketch: 0.0328, G: 6.2583, Cycle: 2.7720, Identity: 1.5985\n",
      "[Train] Epoch 2/20 - Batch 150/225, D_face: 0.0252, D_sketch: 0.0346, G: 6.4654, Cycle: 2.7501, Identity: 1.6485\n",
      "[Train] Epoch 2/20 - Batch 160/225, D_face: 0.0179, D_sketch: 0.2298, G: 8.1712, Cycle: 4.5306, Identity: 2.2262\n",
      "[Train] Epoch 2/20 - Batch 170/225, D_face: 0.0277, D_sketch: 0.0246, G: 6.8591, Cycle: 3.0900, Identity: 1.7548\n",
      "[Train] Epoch 2/20 - Batch 180/225, D_face: 0.0115, D_sketch: 0.0467, G: 6.5857, Cycle: 2.7424, Identity: 1.4226\n",
      "[Train] Epoch 2/20 - Batch 190/225, D_face: 0.0125, D_sketch: 0.0379, G: 6.2303, Cycle: 2.7644, Identity: 1.4425\n",
      "[Train] Epoch 2/20 - Batch 200/225, D_face: 0.0175, D_sketch: 0.0538, G: 8.5987, Cycle: 4.4641, Identity: 2.5148\n",
      "[Train] Epoch 2/20 - Batch 210/225, D_face: 0.0112, D_sketch: 0.0311, G: 8.2568, Cycle: 4.2205, Identity: 2.1914\n",
      "[Train] Epoch 2/20 - Batch 220/225, D_face: 0.0542, D_sketch: 0.0182, G: 8.1587, Cycle: 3.9645, Identity: 2.0156\n",
      "[Train] Epoch 2/20 - Batch 225/225, D_face: 0.0168, D_sketch: 0.0481, G: 6.7978, Cycle: 3.1611, Identity: 1.6623\n",
      "[Train] Epoch 2/20, D_face_loss: 0.0282, D_sketch_loss: 0.0562, G_face2sketch_loss: 0.9609, G_sketch2face_loss: 0.9921, cycle_loss: 3.8049, identity_loss: 2.0849, total_G_loss: 7.8429\n",
      "[Validation] Epoch 2/20, D_face_loss: 0.0257, D_sketch_loss: 0.0373, G_face2sketch_loss: 0.9942, G_sketch2face_loss: 1.0900, cycle_loss: 3.5329, identity_loss: 1.6185, total_G_loss: 7.2357\n",
      "Epoch 2 completed in 22.05 seconds\n",
      "[Train] Epoch 3/20 - Batch 10/225, D_face: 0.0146, D_sketch: 0.0168, G: 8.7521, Cycle: 4.6727, Identity: 2.0651\n",
      "[Train] Epoch 3/20 - Batch 20/225, D_face: 0.0185, D_sketch: 0.0242, G: 7.2989, Cycle: 3.5759, Identity: 2.0877\n",
      "[Train] Epoch 3/20 - Batch 30/225, D_face: 0.0171, D_sketch: 0.0766, G: 7.8071, Cycle: 3.8414, Identity: 1.8954\n",
      "[Train] Epoch 3/20 - Batch 40/225, D_face: 0.0109, D_sketch: 0.0530, G: 8.5056, Cycle: 5.0568, Identity: 1.8885\n",
      "[Train] Epoch 3/20 - Batch 50/225, D_face: 0.0091, D_sketch: 0.0251, G: 5.4827, Cycle: 2.0588, Identity: 1.2298\n",
      "[Train] Epoch 3/20 - Batch 60/225, D_face: 0.0144, D_sketch: 0.0155, G: 6.1107, Cycle: 2.7594, Identity: 1.4586\n",
      "[Train] Epoch 3/20 - Batch 70/225, D_face: 0.0110, D_sketch: 0.0279, G: 8.8103, Cycle: 4.8434, Identity: 2.0885\n",
      "[Train] Epoch 3/20 - Batch 80/225, D_face: 0.0389, D_sketch: 0.0342, G: 5.6854, Cycle: 2.7404, Identity: 1.5625\n",
      "[Train] Epoch 3/20 - Batch 90/225, D_face: 0.0147, D_sketch: 0.0178, G: 7.8771, Cycle: 4.0820, Identity: 2.0038\n",
      "[Train] Epoch 3/20 - Batch 100/225, D_face: 0.0494, D_sketch: 0.0208, G: 7.5744, Cycle: 3.4851, Identity: 1.9897\n",
      "[Train] Epoch 3/20 - Batch 110/225, D_face: 0.0116, D_sketch: 0.0222, G: 5.6714, Cycle: 2.3539, Identity: 1.3158\n",
      "[Train] Epoch 3/20 - Batch 120/225, D_face: 0.0103, D_sketch: 0.0657, G: 8.3784, Cycle: 4.2212, Identity: 2.6167\n",
      "[Train] Epoch 3/20 - Batch 130/225, D_face: 0.0179, D_sketch: 0.0178, G: 6.2673, Cycle: 2.6991, Identity: 1.4884\n",
      "[Train] Epoch 3/20 - Batch 140/225, D_face: 0.0215, D_sketch: 0.0247, G: 9.1401, Cycle: 5.0749, Identity: 2.1514\n",
      "[Train] Epoch 3/20 - Batch 150/225, D_face: 0.0254, D_sketch: 0.0242, G: 8.0816, Cycle: 4.3486, Identity: 2.0317\n",
      "[Train] Epoch 3/20 - Batch 160/225, D_face: 0.0087, D_sketch: 0.0171, G: 6.7570, Cycle: 3.4030, Identity: 1.4204\n",
      "[Train] Epoch 3/20 - Batch 170/225, D_face: 0.0156, D_sketch: 0.0222, G: 6.1367, Cycle: 2.8294, Identity: 1.5587\n",
      "[Train] Epoch 3/20 - Batch 180/225, D_face: 0.3501, D_sketch: 0.0848, G: 13.1074, Cycle: 7.3675, Identity: 4.3819\n",
      "[Train] Epoch 3/20 - Batch 190/225, D_face: 0.0544, D_sketch: 0.0269, G: 6.5390, Cycle: 3.2456, Identity: 1.5040\n",
      "[Train] Epoch 3/20 - Batch 200/225, D_face: 0.0184, D_sketch: 0.0155, G: 8.4716, Cycle: 4.7436, Identity: 1.9242\n",
      "[Train] Epoch 3/20 - Batch 210/225, D_face: 0.0205, D_sketch: 0.0182, G: 7.2897, Cycle: 3.8233, Identity: 1.7556\n",
      "[Train] Epoch 3/20 - Batch 220/225, D_face: 0.0105, D_sketch: 0.0144, G: 5.5031, Cycle: 2.2763, Identity: 1.0788\n",
      "[Train] Epoch 3/20 - Batch 225/225, D_face: 0.0106, D_sketch: 0.0165, G: 7.1425, Cycle: 3.6154, Identity: 1.5708\n",
      "[Train] Epoch 3/20, D_face_loss: 0.0285, D_sketch_loss: 0.0308, G_face2sketch_loss: 0.9860, G_sketch2face_loss: 0.9821, cycle_loss: 3.3370, identity_loss: 1.7099, total_G_loss: 7.0150\n",
      "[Validation] Epoch 3/20, D_face_loss: 0.0186, D_sketch_loss: 0.0299, G_face2sketch_loss: 0.9688, G_sketch2face_loss: 0.8683, cycle_loss: 2.6663, identity_loss: 1.4727, total_G_loss: 5.9761\n",
      "Epoch 3 completed in 21.99 seconds\n",
      "[Train] Epoch 4/20 - Batch 10/225, D_face: 0.0079, D_sketch: 0.0216, G: 6.3706, Cycle: 2.9422, Identity: 1.3390\n",
      "[Train] Epoch 4/20 - Batch 20/225, D_face: 0.0061, D_sketch: 0.0209, G: 6.4856, Cycle: 3.0312, Identity: 1.5868\n",
      "[Train] Epoch 4/20 - Batch 30/225, D_face: 0.0088, D_sketch: 0.0131, G: 5.2127, Cycle: 2.1696, Identity: 1.0240\n",
      "[Train] Epoch 4/20 - Batch 40/225, D_face: 0.0142, D_sketch: 0.0089, G: 6.1023, Cycle: 2.7129, Identity: 1.4431\n",
      "[Train] Epoch 4/20 - Batch 50/225, D_face: 0.0109, D_sketch: 0.0194, G: 5.9361, Cycle: 2.4960, Identity: 1.3230\n",
      "[Train] Epoch 4/20 - Batch 60/225, D_face: 0.0421, D_sketch: 0.0124, G: 6.7017, Cycle: 3.3224, Identity: 1.9306\n",
      "[Train] Epoch 4/20 - Batch 70/225, D_face: 0.0089, D_sketch: 0.0199, G: 7.2584, Cycle: 3.3625, Identity: 1.7298\n",
      "[Train] Epoch 4/20 - Batch 80/225, D_face: 0.0091, D_sketch: 0.0141, G: 5.7913, Cycle: 2.3846, Identity: 1.2368\n",
      "[Train] Epoch 4/20 - Batch 90/225, D_face: 0.0078, D_sketch: 0.0413, G: 14.6695, Cycle: 10.0012, Identity: 3.2677\n",
      "[Train] Epoch 4/20 - Batch 100/225, D_face: 0.0093, D_sketch: 0.0134, G: 5.5597, Cycle: 2.3287, Identity: 1.3490\n",
      "[Train] Epoch 4/20 - Batch 110/225, D_face: 0.0439, D_sketch: 0.0199, G: 7.3341, Cycle: 3.6680, Identity: 1.9103\n",
      "[Train] Epoch 4/20 - Batch 120/225, D_face: 0.0054, D_sketch: 0.0092, G: 5.3719, Cycle: 2.2685, Identity: 1.1226\n",
      "[Train] Epoch 4/20 - Batch 130/225, D_face: 0.0135, D_sketch: 0.0157, G: 5.4257, Cycle: 2.0896, Identity: 1.2917\n",
      "[Train] Epoch 4/20 - Batch 140/225, D_face: 0.0042, D_sketch: 0.0172, G: 5.8169, Cycle: 2.4926, Identity: 1.2485\n",
      "[Train] Epoch 4/20 - Batch 150/225, D_face: 0.0074, D_sketch: 0.0187, G: 5.0973, Cycle: 1.9968, Identity: 0.9983\n",
      "[Train] Epoch 4/20 - Batch 160/225, D_face: 0.0069, D_sketch: 0.0099, G: 6.6594, Cycle: 3.1986, Identity: 1.3179\n",
      "[Train] Epoch 4/20 - Batch 170/225, D_face: 0.0037, D_sketch: 0.0086, G: 4.6237, Cycle: 1.7359, Identity: 0.9187\n",
      "[Train] Epoch 4/20 - Batch 180/225, D_face: 0.0075, D_sketch: 0.0074, G: 5.4351, Cycle: 2.0576, Identity: 1.2261\n",
      "[Train] Epoch 4/20 - Batch 190/225, D_face: 0.0125, D_sketch: 0.0204, G: 7.3465, Cycle: 3.5550, Identity: 1.7470\n",
      "[Train] Epoch 4/20 - Batch 200/225, D_face: 0.0094, D_sketch: 0.0134, G: 7.0907, Cycle: 3.4021, Identity: 1.8733\n",
      "[Train] Epoch 4/20 - Batch 210/225, D_face: 0.0073, D_sketch: 0.0562, G: 5.2521, Cycle: 2.0595, Identity: 1.2000\n",
      "[Train] Epoch 4/20 - Batch 220/225, D_face: 0.0190, D_sketch: 0.0305, G: 13.1454, Cycle: 8.5767, Identity: 2.4749\n",
      "[Train] Epoch 4/20 - Batch 225/225, D_face: 0.0157, D_sketch: 0.0327, G: 7.9070, Cycle: 3.6898, Identity: 2.1077\n",
      "[Train] Epoch 4/20, D_face_loss: 0.0152, D_sketch_loss: 0.0204, G_face2sketch_loss: 0.9896, G_sketch2face_loss: 1.0014, cycle_loss: 2.9101, identity_loss: 1.4545, total_G_loss: 6.3555\n",
      "[Validation] Epoch 4/20, D_face_loss: 0.0139, D_sketch_loss: 0.0249, G_face2sketch_loss: 1.0087, G_sketch2face_loss: 0.8759, cycle_loss: 3.0078, identity_loss: 1.8256, total_G_loss: 6.7180\n",
      "Epoch 4 completed in 21.93 seconds\n",
      "[Train] Epoch 5/20 - Batch 10/225, D_face: 0.0088, D_sketch: 0.0128, G: 7.3577, Cycle: 3.2610, Identity: 1.9913\n",
      "[Train] Epoch 5/20 - Batch 20/225, D_face: 0.0057, D_sketch: 0.0125, G: 7.0577, Cycle: 3.1750, Identity: 1.7841\n",
      "[Train] Epoch 5/20 - Batch 30/225, D_face: 0.0062, D_sketch: 0.0108, G: 5.8085, Cycle: 2.5939, Identity: 1.2941\n",
      "[Train] Epoch 5/20 - Batch 40/225, D_face: 0.0042, D_sketch: 0.0085, G: 5.2119, Cycle: 2.1305, Identity: 1.1332\n",
      "[Train] Epoch 5/20 - Batch 50/225, D_face: 0.0052, D_sketch: 0.0274, G: 5.7131, Cycle: 2.4417, Identity: 1.2738\n",
      "[Train] Epoch 5/20 - Batch 60/225, D_face: 0.0081, D_sketch: 0.0105, G: 7.1887, Cycle: 3.5611, Identity: 1.5314\n",
      "[Train] Epoch 5/20 - Batch 70/225, D_face: 0.0077, D_sketch: 0.0100, G: 7.1049, Cycle: 3.4816, Identity: 1.6848\n",
      "[Train] Epoch 5/20 - Batch 80/225, D_face: 0.0072, D_sketch: 0.0285, G: 5.8715, Cycle: 2.7307, Identity: 1.4744\n",
      "[Train] Epoch 5/20 - Batch 90/225, D_face: 0.0039, D_sketch: 0.0383, G: 5.8241, Cycle: 2.6494, Identity: 1.3088\n",
      "[Train] Epoch 5/20 - Batch 100/225, D_face: 0.0055, D_sketch: 0.0194, G: 5.0785, Cycle: 1.9822, Identity: 0.9648\n",
      "[Train] Epoch 5/20 - Batch 110/225, D_face: 0.0026, D_sketch: 0.0087, G: 6.1421, Cycle: 2.8592, Identity: 1.3723\n",
      "[Train] Epoch 5/20 - Batch 120/225, D_face: 0.0034, D_sketch: 0.0065, G: 6.8034, Cycle: 3.1339, Identity: 1.6963\n",
      "[Train] Epoch 5/20 - Batch 130/225, D_face: 0.0065, D_sketch: 0.0208, G: 7.5264, Cycle: 3.7658, Identity: 1.7364\n",
      "[Train] Epoch 5/20 - Batch 140/225, D_face: 0.0045, D_sketch: 0.0291, G: 4.9848, Cycle: 2.2551, Identity: 1.1052\n",
      "[Train] Epoch 5/20 - Batch 150/225, D_face: 0.0060, D_sketch: 0.0235, G: 6.7292, Cycle: 3.0842, Identity: 1.6239\n",
      "[Train] Epoch 5/20 - Batch 160/225, D_face: 0.0073, D_sketch: 0.0127, G: 7.7587, Cycle: 3.8802, Identity: 1.9737\n",
      "[Train] Epoch 5/20 - Batch 170/225, D_face: 0.0111, D_sketch: 0.0115, G: 5.0025, Cycle: 1.9129, Identity: 1.0266\n",
      "[Train] Epoch 5/20 - Batch 180/225, D_face: 0.0035, D_sketch: 0.0109, G: 5.8217, Cycle: 2.3275, Identity: 1.3483\n",
      "[Train] Epoch 5/20 - Batch 190/225, D_face: 0.0028, D_sketch: 0.0085, G: 5.1907, Cycle: 2.1799, Identity: 1.0591\n",
      "[Train] Epoch 5/20 - Batch 200/225, D_face: 0.0029, D_sketch: 0.0254, G: 5.2574, Cycle: 2.1761, Identity: 1.0806\n",
      "[Train] Epoch 5/20 - Batch 210/225, D_face: 0.0046, D_sketch: 0.0187, G: 5.7786, Cycle: 2.4020, Identity: 1.2594\n",
      "[Train] Epoch 5/20 - Batch 220/225, D_face: 0.0053, D_sketch: 0.0118, G: 6.6553, Cycle: 2.8841, Identity: 1.8631\n",
      "[Train] Epoch 5/20 - Batch 225/225, D_face: 0.0033, D_sketch: 0.0136, G: 4.8279, Cycle: 1.8453, Identity: 0.9441\n",
      "[Train] Epoch 5/20, D_face_loss: 0.0055, D_sketch_loss: 0.0146, G_face2sketch_loss: 0.9954, G_sketch2face_loss: 1.0027, cycle_loss: 2.7069, identity_loss: 1.3784, total_G_loss: 6.0833\n",
      "[Validation] Epoch 5/20, D_face_loss: 0.0054, D_sketch_loss: 0.0181, G_face2sketch_loss: 1.0369, G_sketch2face_loss: 0.9756, cycle_loss: 2.3979, identity_loss: 1.2522, total_G_loss: 5.6627\n",
      "Epoch 5 completed in 23.17 seconds\n",
      "[Train] Epoch 6/20 - Batch 10/225, D_face: 0.0026, D_sketch: 0.0178, G: 6.1305, Cycle: 2.5539, Identity: 1.3325\n",
      "[Train] Epoch 6/20 - Batch 20/225, D_face: 0.0045, D_sketch: 0.0350, G: 5.5818, Cycle: 2.3090, Identity: 1.1026\n",
      "[Train] Epoch 6/20 - Batch 30/225, D_face: 0.0030, D_sketch: 0.0099, G: 7.9879, Cycle: 3.8207, Identity: 2.2078\n",
      "[Train] Epoch 6/20 - Batch 40/225, D_face: 0.0020, D_sketch: 0.0107, G: 4.6462, Cycle: 1.5782, Identity: 0.9111\n",
      "[Train] Epoch 6/20 - Batch 50/225, D_face: 0.0048, D_sketch: 0.0077, G: 5.5011, Cycle: 2.4385, Identity: 1.0629\n",
      "[Train] Epoch 6/20 - Batch 60/225, D_face: 0.0017, D_sketch: 0.0105, G: 4.7469, Cycle: 1.8918, Identity: 0.8447\n",
      "[Train] Epoch 6/20 - Batch 70/225, D_face: 0.0026, D_sketch: 0.0316, G: 6.9340, Cycle: 3.3608, Identity: 1.5692\n",
      "[Train] Epoch 6/20 - Batch 80/225, D_face: 0.0015, D_sketch: 0.0094, G: 4.3228, Cycle: 1.4624, Identity: 0.7232\n",
      "[Train] Epoch 6/20 - Batch 90/225, D_face: 0.0031, D_sketch: 0.0150, G: 5.3155, Cycle: 2.1136, Identity: 1.0802\n",
      "[Train] Epoch 6/20 - Batch 100/225, D_face: 0.0047, D_sketch: 0.0234, G: 5.5512, Cycle: 2.3324, Identity: 1.2235\n",
      "[Train] Epoch 6/20 - Batch 110/225, D_face: 0.0024, D_sketch: 0.0104, G: 5.3232, Cycle: 2.1315, Identity: 1.0746\n",
      "[Train] Epoch 6/20 - Batch 120/225, D_face: 0.0039, D_sketch: 0.0454, G: 7.6099, Cycle: 3.6609, Identity: 1.7465\n",
      "[Train] Epoch 6/20 - Batch 130/225, D_face: 0.0033, D_sketch: 0.0053, G: 6.1587, Cycle: 2.8587, Identity: 1.3934\n",
      "[Train] Epoch 6/20 - Batch 140/225, D_face: 0.0024, D_sketch: 0.0102, G: 6.2390, Cycle: 2.9143, Identity: 1.3442\n",
      "[Train] Epoch 6/20 - Batch 150/225, D_face: 0.0120, D_sketch: 0.0174, G: 4.9736, Cycle: 1.9077, Identity: 0.9908\n",
      "[Train] Epoch 6/20 - Batch 160/225, D_face: 0.0050, D_sketch: 0.0177, G: 4.5066, Cycle: 1.4690, Identity: 0.8597\n",
      "[Train] Epoch 6/20 - Batch 170/225, D_face: 0.0091, D_sketch: 0.0127, G: 6.5549, Cycle: 2.9774, Identity: 1.6387\n",
      "[Train] Epoch 6/20 - Batch 180/225, D_face: 0.0026, D_sketch: 0.0054, G: 4.8495, Cycle: 1.7926, Identity: 0.8604\n",
      "[Train] Epoch 6/20 - Batch 190/225, D_face: 0.0031, D_sketch: 0.0173, G: 4.5086, Cycle: 1.5388, Identity: 0.8431\n",
      "[Train] Epoch 6/20 - Batch 200/225, D_face: 0.0034, D_sketch: 0.0152, G: 5.8546, Cycle: 2.5977, Identity: 1.1925\n",
      "[Train] Epoch 6/20 - Batch 210/225, D_face: 0.0056, D_sketch: 0.0081, G: 6.4919, Cycle: 3.1893, Identity: 1.3390\n",
      "[Train] Epoch 6/20 - Batch 220/225, D_face: 0.0047, D_sketch: 0.0189, G: 7.1629, Cycle: 3.0933, Identity: 1.9245\n",
      "[Train] Epoch 6/20 - Batch 225/225, D_face: 0.0017, D_sketch: 0.0118, G: 5.1702, Cycle: 1.6945, Identity: 1.3374\n",
      "[Train] Epoch 6/20, D_face_loss: 0.0043, D_sketch_loss: 0.0156, G_face2sketch_loss: 0.9927, G_sketch2face_loss: 0.9988, cycle_loss: 2.5653, identity_loss: 1.2777, total_G_loss: 5.8345\n",
      "[Validation] Epoch 6/20, D_face_loss: 0.0033, D_sketch_loss: 0.0142, G_face2sketch_loss: 1.0027, G_sketch2face_loss: 1.0058, cycle_loss: 2.7036, identity_loss: 1.4658, total_G_loss: 6.1779\n",
      "Epoch 6 completed in 22.15 seconds\n",
      "[Train] Epoch 7/20 - Batch 10/225, D_face: 0.0089, D_sketch: 0.0095, G: 6.9400, Cycle: 3.5166, Identity: 1.5249\n",
      "[Train] Epoch 7/20 - Batch 20/225, D_face: 0.0017, D_sketch: 0.0065, G: 4.5329, Cycle: 1.5236, Identity: 1.0082\n",
      "[Train] Epoch 7/20 - Batch 30/225, D_face: 0.0047, D_sketch: 0.0101, G: 7.0174, Cycle: 3.3874, Identity: 1.6866\n",
      "[Train] Epoch 7/20 - Batch 40/225, D_face: 0.0055, D_sketch: 0.0112, G: 6.5903, Cycle: 2.9303, Identity: 1.5438\n",
      "[Train] Epoch 7/20 - Batch 50/225, D_face: 0.0040, D_sketch: 0.0080, G: 4.4401, Cycle: 1.4963, Identity: 0.9529\n",
      "[Train] Epoch 7/20 - Batch 60/225, D_face: 0.0023, D_sketch: 0.0177, G: 6.2864, Cycle: 2.7009, Identity: 1.4792\n",
      "[Train] Epoch 7/20 - Batch 70/225, D_face: 0.0025, D_sketch: 0.0110, G: 4.4631, Cycle: 1.6497, Identity: 0.7950\n",
      "[Train] Epoch 7/20 - Batch 80/225, D_face: 0.0017, D_sketch: 0.0066, G: 5.3618, Cycle: 2.0284, Identity: 1.2757\n",
      "[Train] Epoch 7/20 - Batch 90/225, D_face: 0.0066, D_sketch: 0.0065, G: 4.5098, Cycle: 1.7070, Identity: 0.8411\n",
      "[Train] Epoch 7/20 - Batch 100/225, D_face: 0.0023, D_sketch: 0.0072, G: 5.5047, Cycle: 2.2741, Identity: 1.2899\n",
      "[Train] Epoch 7/20 - Batch 110/225, D_face: 0.0474, D_sketch: 0.0117, G: 7.1434, Cycle: 3.6530, Identity: 1.8333\n",
      "[Train] Epoch 7/20 - Batch 120/225, D_face: 0.0078, D_sketch: 0.0176, G: 7.0181, Cycle: 3.7622, Identity: 1.3579\n",
      "[Train] Epoch 7/20 - Batch 130/225, D_face: 0.0071, D_sketch: 0.0063, G: 5.2716, Cycle: 2.1467, Identity: 1.0980\n",
      "[Train] Epoch 7/20 - Batch 140/225, D_face: 0.0035, D_sketch: 0.0092, G: 7.2409, Cycle: 3.5037, Identity: 1.9193\n",
      "[Train] Epoch 7/20 - Batch 150/225, D_face: 0.0071, D_sketch: 0.0089, G: 4.6573, Cycle: 1.7916, Identity: 0.9551\n",
      "[Train] Epoch 7/20 - Batch 160/225, D_face: 0.0040, D_sketch: 0.0526, G: 5.7690, Cycle: 2.0927, Identity: 1.0786\n",
      "[Train] Epoch 7/20 - Batch 170/225, D_face: 0.0021, D_sketch: 0.0096, G: 4.6697, Cycle: 1.9078, Identity: 0.8567\n",
      "[Train] Epoch 7/20 - Batch 180/225, D_face: 0.0037, D_sketch: 0.0080, G: 6.8973, Cycle: 3.1662, Identity: 1.5973\n",
      "[Train] Epoch 7/20 - Batch 190/225, D_face: 0.0025, D_sketch: 0.0168, G: 5.3320, Cycle: 2.2361, Identity: 1.0980\n",
      "[Train] Epoch 7/20 - Batch 200/225, D_face: 0.0018, D_sketch: 0.0093, G: 4.1068, Cycle: 1.3590, Identity: 0.7705\n",
      "[Train] Epoch 7/20 - Batch 210/225, D_face: 0.0037, D_sketch: 0.0099, G: 5.9777, Cycle: 2.8188, Identity: 1.3101\n",
      "[Train] Epoch 7/20 - Batch 220/225, D_face: 0.0019, D_sketch: 0.0045, G: 5.6727, Cycle: 2.0546, Identity: 1.6017\n",
      "[Train] Epoch 7/20 - Batch 225/225, D_face: 0.0025, D_sketch: 0.0106, G: 6.5853, Cycle: 3.0765, Identity: 1.4369\n",
      "[Train] Epoch 7/20, D_face_loss: 0.0066, D_sketch_loss: 0.0111, G_face2sketch_loss: 0.9872, G_sketch2face_loss: 1.0052, cycle_loss: 2.4458, identity_loss: 1.2601, total_G_loss: 5.6984\n",
      "[Validation] Epoch 7/20, D_face_loss: 0.0069, D_sketch_loss: 0.0165, G_face2sketch_loss: 0.9784, G_sketch2face_loss: 0.9699, cycle_loss: 2.4737, identity_loss: 1.2864, total_G_loss: 5.7085\n",
      "Epoch 7 completed in 22.22 seconds\n",
      "[Train] Epoch 8/20 - Batch 10/225, D_face: 0.0022, D_sketch: 0.0038, G: 4.5967, Cycle: 1.7016, Identity: 0.9337\n",
      "[Train] Epoch 8/20 - Batch 20/225, D_face: 0.0021, D_sketch: 0.0122, G: 5.9517, Cycle: 2.6974, Identity: 1.1614\n",
      "[Train] Epoch 8/20 - Batch 30/225, D_face: 0.0030, D_sketch: 0.0092, G: 5.6427, Cycle: 2.3408, Identity: 1.2302\n",
      "[Train] Epoch 8/20 - Batch 40/225, D_face: 0.0033, D_sketch: 0.0049, G: 5.8325, Cycle: 2.4966, Identity: 1.2272\n",
      "[Train] Epoch 8/20 - Batch 50/225, D_face: 0.0020, D_sketch: 0.0040, G: 5.5598, Cycle: 2.3138, Identity: 1.1358\n",
      "[Train] Epoch 8/20 - Batch 60/225, D_face: 0.0031, D_sketch: 0.0053, G: 6.3813, Cycle: 2.9794, Identity: 1.5352\n",
      "[Train] Epoch 8/20 - Batch 70/225, D_face: 0.0037, D_sketch: 0.0048, G: 6.1223, Cycle: 2.7459, Identity: 1.4589\n",
      "[Train] Epoch 8/20 - Batch 80/225, D_face: 0.0018, D_sketch: 0.0035, G: 4.7031, Cycle: 1.7914, Identity: 0.9057\n",
      "[Train] Epoch 8/20 - Batch 90/225, D_face: 0.0049, D_sketch: 0.0084, G: 6.4789, Cycle: 3.0072, Identity: 1.6206\n",
      "[Train] Epoch 8/20 - Batch 100/225, D_face: 0.0019, D_sketch: 0.0035, G: 4.1511, Cycle: 1.3887, Identity: 0.7020\n",
      "[Train] Epoch 8/20 - Batch 110/225, D_face: 0.0028, D_sketch: 0.0164, G: 7.6585, Cycle: 3.7409, Identity: 1.7635\n",
      "[Train] Epoch 8/20 - Batch 120/225, D_face: 0.0027, D_sketch: 0.0099, G: 6.3251, Cycle: 3.0261, Identity: 1.4040\n",
      "[Train] Epoch 8/20 - Batch 130/225, D_face: 0.0016, D_sketch: 0.0062, G: 5.1451, Cycle: 2.0715, Identity: 1.0888\n",
      "[Train] Epoch 8/20 - Batch 140/225, D_face: 0.0019, D_sketch: 0.0073, G: 5.8839, Cycle: 2.5705, Identity: 1.2081\n",
      "[Train] Epoch 8/20 - Batch 150/225, D_face: 0.0024, D_sketch: 0.0037, G: 5.4475, Cycle: 2.2558, Identity: 1.2069\n",
      "[Train] Epoch 8/20 - Batch 160/225, D_face: 0.0033, D_sketch: 0.0134, G: 4.7106, Cycle: 1.7376, Identity: 0.9035\n",
      "[Train] Epoch 8/20 - Batch 170/225, D_face: 0.0018, D_sketch: 0.0124, G: 4.1838, Cycle: 1.3687, Identity: 0.8524\n",
      "[Train] Epoch 8/20 - Batch 180/225, D_face: 0.0063, D_sketch: 0.0149, G: 6.7363, Cycle: 3.1458, Identity: 1.5524\n",
      "[Train] Epoch 8/20 - Batch 190/225, D_face: 0.0017, D_sketch: 0.0142, G: 4.2413, Cycle: 1.4424, Identity: 0.8555\n",
      "[Train] Epoch 8/20 - Batch 200/225, D_face: 0.0028, D_sketch: 0.0118, G: 6.2621, Cycle: 2.6184, Identity: 1.7314\n",
      "[Train] Epoch 8/20 - Batch 210/225, D_face: 0.0018, D_sketch: 0.0142, G: 4.5885, Cycle: 1.6299, Identity: 0.8065\n",
      "[Train] Epoch 8/20 - Batch 220/225, D_face: 0.0027, D_sketch: 0.0179, G: 5.1372, Cycle: 2.0621, Identity: 1.1784\n",
      "[Train] Epoch 8/20 - Batch 225/225, D_face: 0.0053, D_sketch: 0.0214, G: 3.8804, Cycle: 1.0530, Identity: 0.7062\n",
      "[Train] Epoch 8/20, D_face_loss: 0.0028, D_sketch_loss: 0.0123, G_face2sketch_loss: 0.9888, G_sketch2face_loss: 0.9973, cycle_loss: 2.2761, identity_loss: 1.1586, total_G_loss: 5.4209\n",
      "[Validation] Epoch 8/20, D_face_loss: 0.0042, D_sketch_loss: 0.0163, G_face2sketch_loss: 1.0675, G_sketch2face_loss: 0.9584, cycle_loss: 2.5885, identity_loss: 1.1885, total_G_loss: 5.8030\n",
      "Epoch 8 completed in 21.97 seconds\n",
      "[Train] Epoch 9/20 - Batch 10/225, D_face: 0.0019, D_sketch: 0.0074, G: 4.0635, Cycle: 1.3668, Identity: 0.7010\n",
      "[Train] Epoch 9/20 - Batch 20/225, D_face: 0.0155, D_sketch: 0.0040, G: 5.0852, Cycle: 2.0953, Identity: 0.9016\n",
      "[Train] Epoch 9/20 - Batch 30/225, D_face: 0.0146, D_sketch: 0.0073, G: 5.0347, Cycle: 2.0177, Identity: 0.9560\n",
      "[Train] Epoch 9/20 - Batch 40/225, D_face: 0.0056, D_sketch: 0.0087, G: 6.3472, Cycle: 2.7713, Identity: 1.4486\n",
      "[Train] Epoch 9/20 - Batch 50/225, D_face: 0.0077, D_sketch: 0.0333, G: 8.1801, Cycle: 4.2303, Identity: 1.9375\n",
      "[Train] Epoch 9/20 - Batch 60/225, D_face: 0.0032, D_sketch: 0.0229, G: 14.7461, Cycle: 11.0368, Identity: 1.8267\n",
      "[Train] Epoch 9/20 - Batch 70/225, D_face: 0.0067, D_sketch: 0.0297, G: 8.3702, Cycle: 4.4699, Identity: 1.8224\n",
      "[Train] Epoch 9/20 - Batch 80/225, D_face: 0.0018, D_sketch: 0.0127, G: 8.3809, Cycle: 5.0875, Identity: 1.3313\n",
      "[Train] Epoch 9/20 - Batch 90/225, D_face: 0.0035, D_sketch: 0.0094, G: 7.0408, Cycle: 3.3628, Identity: 1.6219\n",
      "[Train] Epoch 9/20 - Batch 100/225, D_face: 0.0027, D_sketch: 0.0091, G: 7.5787, Cycle: 4.3047, Identity: 1.3337\n",
      "[Train] Epoch 9/20 - Batch 110/225, D_face: 0.0030, D_sketch: 0.0065, G: 4.7870, Cycle: 1.9457, Identity: 0.9397\n",
      "[Train] Epoch 9/20 - Batch 120/225, D_face: 0.0013, D_sketch: 0.0062, G: 4.8449, Cycle: 1.9693, Identity: 0.8724\n",
      "[Train] Epoch 9/20 - Batch 130/225, D_face: 0.0019, D_sketch: 0.0115, G: 6.7161, Cycle: 3.2332, Identity: 1.3902\n",
      "[Train] Epoch 9/20 - Batch 140/225, D_face: 0.0020, D_sketch: 0.0051, G: 5.5674, Cycle: 2.2664, Identity: 1.2845\n",
      "[Train] Epoch 9/20 - Batch 150/225, D_face: 0.0032, D_sketch: 0.0054, G: 6.2181, Cycle: 2.9447, Identity: 1.3354\n",
      "[Train] Epoch 9/20 - Batch 160/225, D_face: 0.0019, D_sketch: 0.0087, G: 6.5900, Cycle: 2.9829, Identity: 1.5450\n",
      "[Train] Epoch 9/20 - Batch 170/225, D_face: 0.0021, D_sketch: 0.0052, G: 5.2517, Cycle: 2.2195, Identity: 0.9849\n",
      "[Train] Epoch 9/20 - Batch 180/225, D_face: 0.0026, D_sketch: 0.0160, G: 4.5808, Cycle: 1.7038, Identity: 1.0284\n",
      "[Train] Epoch 9/20 - Batch 190/225, D_face: 0.0074, D_sketch: 0.0146, G: 5.2238, Cycle: 2.1620, Identity: 1.1413\n",
      "[Train] Epoch 9/20 - Batch 200/225, D_face: 0.0024, D_sketch: 0.0065, G: 4.8911, Cycle: 1.8587, Identity: 1.0332\n",
      "[Train] Epoch 9/20 - Batch 210/225, D_face: 0.0018, D_sketch: 0.0125, G: 5.9774, Cycle: 2.3766, Identity: 1.5773\n",
      "[Train] Epoch 9/20 - Batch 220/225, D_face: 0.0033, D_sketch: 0.0085, G: 4.8925, Cycle: 1.9913, Identity: 0.9245\n",
      "[Train] Epoch 9/20 - Batch 225/225, D_face: 0.0034, D_sketch: 0.0049, G: 5.5828, Cycle: 2.4182, Identity: 1.1652\n",
      "[Train] Epoch 9/20, D_face_loss: 0.0113, D_sketch_loss: 0.0181, G_face2sketch_loss: 0.9951, G_sketch2face_loss: 1.0080, cycle_loss: 2.8272, identity_loss: 1.2745, total_G_loss: 6.1049\n",
      "[Validation] Epoch 9/20, D_face_loss: 0.0036, D_sketch_loss: 0.0072, G_face2sketch_loss: 0.9457, G_sketch2face_loss: 0.9888, cycle_loss: 2.3860, identity_loss: 1.1988, total_G_loss: 5.5193\n",
      "Epoch 9 completed in 22.21 seconds\n",
      "[Train] Epoch 10/20 - Batch 10/225, D_face: 0.0037, D_sketch: 0.0080, G: 6.9057, Cycle: 3.3418, Identity: 1.7064\n",
      "[Train] Epoch 10/20 - Batch 20/225, D_face: 0.0019, D_sketch: 0.0048, G: 4.6819, Cycle: 1.7353, Identity: 0.9370\n",
      "[Train] Epoch 10/20 - Batch 30/225, D_face: 0.0030, D_sketch: 0.0035, G: 4.9886, Cycle: 2.0494, Identity: 0.9901\n",
      "[Train] Epoch 10/20 - Batch 40/225, D_face: 0.0019, D_sketch: 0.0132, G: 5.4794, Cycle: 2.4462, Identity: 1.1239\n",
      "[Train] Epoch 10/20 - Batch 50/225, D_face: 0.0017, D_sketch: 0.0050, G: 5.3986, Cycle: 2.2180, Identity: 1.1378\n",
      "[Train] Epoch 10/20 - Batch 60/225, D_face: 0.0012, D_sketch: 0.0069, G: 4.6565, Cycle: 1.8185, Identity: 0.8226\n",
      "[Train] Epoch 10/20 - Batch 70/225, D_face: 0.0026, D_sketch: 0.0075, G: 5.1642, Cycle: 2.1571, Identity: 1.0350\n",
      "[Train] Epoch 10/20 - Batch 80/225, D_face: 0.0013, D_sketch: 0.0089, G: 5.7123, Cycle: 2.5189, Identity: 1.0380\n",
      "[Train] Epoch 10/20 - Batch 90/225, D_face: 0.0026, D_sketch: 0.0223, G: 10.1114, Cycle: 7.0866, Identity: 1.1227\n",
      "[Train] Epoch 10/20 - Batch 100/225, D_face: 0.1973, D_sketch: 0.0288, G: 7.1406, Cycle: 2.5305, Identity: 1.9808\n",
      "[Train] Epoch 10/20 - Batch 110/225, D_face: 0.0254, D_sketch: 0.0116, G: 7.2812, Cycle: 3.6091, Identity: 1.7405\n",
      "[Train] Epoch 10/20 - Batch 120/225, D_face: 0.0117, D_sketch: 0.0048, G: 4.4559, Cycle: 1.4159, Identity: 1.0362\n",
      "[Train] Epoch 10/20 - Batch 130/225, D_face: 0.0032, D_sketch: 0.0229, G: 7.5701, Cycle: 4.0644, Identity: 1.5931\n",
      "[Train] Epoch 10/20 - Batch 140/225, D_face: 0.0040, D_sketch: 0.0143, G: 4.1572, Cycle: 1.3813, Identity: 0.8188\n",
      "[Train] Epoch 10/20 - Batch 150/225, D_face: 0.0144, D_sketch: 0.0215, G: 5.3711, Cycle: 2.2598, Identity: 1.0122\n",
      "[Train] Epoch 10/20 - Batch 160/225, D_face: 0.0015, D_sketch: 0.0046, G: 4.9788, Cycle: 1.9244, Identity: 1.0255\n",
      "[Train] Epoch 10/20 - Batch 170/225, D_face: 0.0055, D_sketch: 0.0054, G: 5.0812, Cycle: 1.9284, Identity: 1.0024\n",
      "[Train] Epoch 10/20 - Batch 180/225, D_face: 0.0029, D_sketch: 0.0092, G: 4.8808, Cycle: 1.8421, Identity: 0.9270\n",
      "[Train] Epoch 10/20 - Batch 190/225, D_face: 0.0027, D_sketch: 0.0054, G: 4.7209, Cycle: 1.8560, Identity: 0.8951\n",
      "[Train] Epoch 10/20 - Batch 200/225, D_face: 0.0024, D_sketch: 0.0066, G: 8.9023, Cycle: 4.7051, Identity: 2.1525\n",
      "[Train] Epoch 10/20 - Batch 210/225, D_face: 0.0073, D_sketch: 0.0073, G: 4.3700, Cycle: 1.5549, Identity: 0.9536\n",
      "[Train] Epoch 10/20 - Batch 220/225, D_face: 0.0025, D_sketch: 0.0081, G: 7.7538, Cycle: 3.9253, Identity: 1.8952\n",
      "[Train] Epoch 10/20 - Batch 225/225, D_face: 0.0018, D_sketch: 0.0088, G: 9.3235, Cycle: 5.2750, Identity: 2.0272\n",
      "[Train] Epoch 10/20, D_face_loss: 0.0264, D_sketch_loss: 0.0127, G_face2sketch_loss: 0.9937, G_sketch2face_loss: 0.9995, cycle_loss: 2.6036, identity_loss: 1.3601, total_G_loss: 5.9569\n",
      "[Validation] Epoch 10/20, D_face_loss: 0.0028, D_sketch_loss: 0.0066, G_face2sketch_loss: 1.0654, G_sketch2face_loss: 0.9709, cycle_loss: 2.2854, identity_loss: 1.1485, total_G_loss: 5.4703\n",
      "Epoch 10 completed in 23.56 seconds\n",
      "[Train] Epoch 11/20 - Batch 10/225, D_face: 0.0029, D_sketch: 0.0053, G: 6.5085, Cycle: 2.8719, Identity: 1.5792\n",
      "[Train] Epoch 11/20 - Batch 20/225, D_face: 0.0016, D_sketch: 0.0043, G: 5.1862, Cycle: 2.1926, Identity: 0.9549\n",
      "[Train] Epoch 11/20 - Batch 30/225, D_face: 0.0028, D_sketch: 0.0035, G: 7.3231, Cycle: 3.7352, Identity: 1.5659\n",
      "[Train] Epoch 11/20 - Batch 40/225, D_face: 0.0036, D_sketch: 0.0049, G: 4.3784, Cycle: 1.5727, Identity: 0.8605\n",
      "[Train] Epoch 11/20 - Batch 50/225, D_face: 0.0015, D_sketch: 0.0067, G: 3.6611, Cycle: 1.0737, Identity: 0.6290\n",
      "[Train] Epoch 11/20 - Batch 60/225, D_face: 0.0021, D_sketch: 0.0031, G: 5.8196, Cycle: 2.5537, Identity: 1.2734\n",
      "[Train] Epoch 11/20 - Batch 70/225, D_face: 0.0015, D_sketch: 0.0058, G: 4.7875, Cycle: 1.8373, Identity: 0.8986\n",
      "[Train] Epoch 11/20 - Batch 80/225, D_face: 0.0034, D_sketch: 0.0037, G: 5.9961, Cycle: 2.8359, Identity: 1.1256\n",
      "[Train] Epoch 11/20 - Batch 90/225, D_face: 0.0017, D_sketch: 0.0091, G: 4.9419, Cycle: 1.8446, Identity: 1.0334\n",
      "[Train] Epoch 11/20 - Batch 100/225, D_face: 0.0013, D_sketch: 0.0078, G: 4.7311, Cycle: 1.9934, Identity: 0.8212\n",
      "[Train] Epoch 11/20 - Batch 110/225, D_face: 0.0006, D_sketch: 0.0022, G: 5.7003, Cycle: 2.4607, Identity: 1.2965\n",
      "[Train] Epoch 11/20 - Batch 120/225, D_face: 0.0016, D_sketch: 0.0051, G: 5.4529, Cycle: 2.2795, Identity: 1.1736\n",
      "[Train] Epoch 11/20 - Batch 130/225, D_face: 0.0014, D_sketch: 0.0074, G: 4.8317, Cycle: 1.9730, Identity: 0.8227\n",
      "[Train] Epoch 11/20 - Batch 140/225, D_face: 0.0046, D_sketch: 0.0084, G: 6.0753, Cycle: 2.7694, Identity: 1.3647\n",
      "[Train] Epoch 11/20 - Batch 150/225, D_face: 0.0013, D_sketch: 0.0054, G: 4.4453, Cycle: 1.7586, Identity: 0.7475\n",
      "[Train] Epoch 11/20 - Batch 160/225, D_face: 0.0012, D_sketch: 0.0018, G: 5.1524, Cycle: 2.0212, Identity: 1.0978\n",
      "[Train] Epoch 11/20 - Batch 170/225, D_face: 0.0028, D_sketch: 0.0063, G: 5.1477, Cycle: 1.9832, Identity: 1.1539\n",
      "[Train] Epoch 11/20 - Batch 180/225, D_face: 0.0069, D_sketch: 0.0079, G: 7.0601, Cycle: 3.5619, Identity: 1.6363\n",
      "[Train] Epoch 11/20 - Batch 190/225, D_face: 0.0046, D_sketch: 0.0028, G: 4.6663, Cycle: 1.7249, Identity: 0.9124\n",
      "[Train] Epoch 11/20 - Batch 200/225, D_face: 0.0015, D_sketch: 0.0052, G: 5.0255, Cycle: 2.0554, Identity: 0.9906\n",
      "[Train] Epoch 11/20 - Batch 210/225, D_face: 0.0013, D_sketch: 0.0032, G: 4.7184, Cycle: 1.8376, Identity: 0.8489\n",
      "[Train] Epoch 11/20 - Batch 220/225, D_face: 0.0018, D_sketch: 0.0050, G: 5.5046, Cycle: 2.3048, Identity: 1.2034\n",
      "[Train] Epoch 11/20 - Batch 225/225, D_face: 0.0013, D_sketch: 0.0049, G: 5.6642, Cycle: 2.6359, Identity: 1.0499\n",
      "[Train] Epoch 11/20, D_face_loss: 0.0021, D_sketch_loss: 0.0057, G_face2sketch_loss: 0.9992, G_sketch2face_loss: 1.0010, cycle_loss: 2.2114, identity_loss: 1.0979, total_G_loss: 5.3095\n",
      "[Validation] Epoch 11/20, D_face_loss: 0.0024, D_sketch_loss: 0.0047, G_face2sketch_loss: 1.0256, G_sketch2face_loss: 0.9778, cycle_loss: 2.1282, identity_loss: 1.0666, total_G_loss: 5.1982\n",
      "Epoch 11 completed in 22.49 seconds\n",
      "[Train] Epoch 12/20 - Batch 10/225, D_face: 0.0017, D_sketch: 0.0024, G: 4.2748, Cycle: 1.4078, Identity: 0.7812\n",
      "[Train] Epoch 12/20 - Batch 20/225, D_face: 0.0014, D_sketch: 0.0038, G: 6.8219, Cycle: 3.0935, Identity: 1.7731\n",
      "[Train] Epoch 12/20 - Batch 30/225, D_face: 0.0009, D_sketch: 0.0052, G: 4.1893, Cycle: 1.4255, Identity: 0.7395\n",
      "[Train] Epoch 12/20 - Batch 40/225, D_face: 0.0587, D_sketch: 0.2105, G: 5.0489, Cycle: 2.6158, Identity: 1.2202\n",
      "[Train] Epoch 12/20 - Batch 50/225, D_face: 0.0111, D_sketch: 0.0265, G: 8.1569, Cycle: 4.4250, Identity: 1.4451\n",
      "[Train] Epoch 12/20 - Batch 60/225, D_face: 0.0103, D_sketch: 0.0256, G: 5.9467, Cycle: 2.8097, Identity: 1.3148\n",
      "[Train] Epoch 12/20 - Batch 70/225, D_face: 0.0037, D_sketch: 0.0042, G: 5.0551, Cycle: 1.9105, Identity: 1.1059\n",
      "[Train] Epoch 12/20 - Batch 80/225, D_face: 0.0013, D_sketch: 0.0134, G: 4.1972, Cycle: 1.3713, Identity: 0.7583\n",
      "[Train] Epoch 12/20 - Batch 90/225, D_face: 0.0049, D_sketch: 0.0067, G: 5.1290, Cycle: 2.1092, Identity: 0.9360\n",
      "[Train] Epoch 12/20 - Batch 100/225, D_face: 0.0061, D_sketch: 0.0097, G: 6.4573, Cycle: 2.9552, Identity: 1.5347\n",
      "[Train] Epoch 12/20 - Batch 110/225, D_face: 0.0054, D_sketch: 0.0044, G: 6.2550, Cycle: 2.9473, Identity: 1.3451\n",
      "[Train] Epoch 12/20 - Batch 120/225, D_face: 0.0053, D_sketch: 0.0069, G: 5.0491, Cycle: 2.1033, Identity: 0.9029\n",
      "[Train] Epoch 12/20 - Batch 130/225, D_face: 0.0040, D_sketch: 0.0029, G: 4.9099, Cycle: 1.8518, Identity: 1.0111\n",
      "[Train] Epoch 12/20 - Batch 140/225, D_face: 0.0014, D_sketch: 0.0204, G: 6.5563, Cycle: 3.2259, Identity: 1.4163\n",
      "[Train] Epoch 12/20 - Batch 150/225, D_face: 0.0033, D_sketch: 0.0045, G: 4.3940, Cycle: 1.5620, Identity: 0.6902\n",
      "[Train] Epoch 12/20 - Batch 160/225, D_face: 0.0008, D_sketch: 0.0090, G: 6.5358, Cycle: 2.8972, Identity: 1.7394\n",
      "[Train] Epoch 12/20 - Batch 170/225, D_face: 0.0017, D_sketch: 0.0027, G: 4.7367, Cycle: 1.7819, Identity: 0.9927\n",
      "[Train] Epoch 12/20 - Batch 180/225, D_face: 0.0018, D_sketch: 0.0062, G: 5.6707, Cycle: 2.3011, Identity: 1.1734\n",
      "[Train] Epoch 12/20 - Batch 190/225, D_face: 0.0013, D_sketch: 0.0053, G: 5.3329, Cycle: 2.3081, Identity: 1.0068\n",
      "[Train] Epoch 12/20 - Batch 200/225, D_face: 0.0009, D_sketch: 0.0023, G: 5.8872, Cycle: 2.5925, Identity: 1.2986\n",
      "[Train] Epoch 12/20 - Batch 210/225, D_face: 0.0008, D_sketch: 0.0042, G: 4.5679, Cycle: 1.7194, Identity: 0.8030\n",
      "[Train] Epoch 12/20 - Batch 220/225, D_face: 0.0010, D_sketch: 0.0048, G: 5.2268, Cycle: 2.1563, Identity: 1.1100\n",
      "[Train] Epoch 12/20 - Batch 225/225, D_face: 0.0016, D_sketch: 0.0048, G: 4.8874, Cycle: 1.9946, Identity: 0.9742\n",
      "[Train] Epoch 12/20, D_face_loss: 0.0087, D_sketch_loss: 0.0137, G_face2sketch_loss: 0.9894, G_sketch2face_loss: 0.9994, cycle_loss: 2.3070, identity_loss: 1.1070, total_G_loss: 5.4028\n",
      "[Validation] Epoch 12/20, D_face_loss: 0.0012, D_sketch_loss: 0.0055, G_face2sketch_loss: 1.0049, G_sketch2face_loss: 0.9955, cycle_loss: 2.0876, identity_loss: 1.0089, total_G_loss: 5.0969\n",
      "Epoch 12 completed in 22.49 seconds\n",
      "[Train] Epoch 13/20 - Batch 10/225, D_face: 0.0011, D_sketch: 0.0186, G: 5.1063, Cycle: 2.0678, Identity: 0.9176\n",
      "[Train] Epoch 13/20 - Batch 20/225, D_face: 0.0024, D_sketch: 0.0014, G: 4.5281, Cycle: 1.6736, Identity: 0.8456\n",
      "[Train] Epoch 13/20 - Batch 30/225, D_face: 0.0015, D_sketch: 0.0021, G: 6.1808, Cycle: 2.7621, Identity: 1.4515\n",
      "[Train] Epoch 13/20 - Batch 40/225, D_face: 0.0008, D_sketch: 0.0035, G: 5.3738, Cycle: 2.4232, Identity: 0.9514\n",
      "[Train] Epoch 13/20 - Batch 50/225, D_face: 0.0021, D_sketch: 0.0031, G: 5.8460, Cycle: 2.6033, Identity: 1.3615\n",
      "[Train] Epoch 13/20 - Batch 60/225, D_face: 0.0016, D_sketch: 0.0037, G: 4.4890, Cycle: 1.5570, Identity: 0.8594\n",
      "[Train] Epoch 13/20 - Batch 70/225, D_face: 0.0008, D_sketch: 0.0496, G: 4.8400, Cycle: 1.5301, Identity: 0.8042\n",
      "[Train] Epoch 13/20 - Batch 80/225, D_face: 0.0004, D_sketch: 0.0039, G: 5.3361, Cycle: 2.2697, Identity: 1.1026\n",
      "[Train] Epoch 13/20 - Batch 90/225, D_face: 0.0022, D_sketch: 0.0066, G: 5.2658, Cycle: 2.4536, Identity: 0.9668\n",
      "[Train] Epoch 13/20 - Batch 100/225, D_face: 0.0011, D_sketch: 0.0038, G: 4.1490, Cycle: 1.3991, Identity: 0.7699\n",
      "[Train] Epoch 13/20 - Batch 110/225, D_face: 0.0116, D_sketch: 0.0063, G: 5.9676, Cycle: 2.5279, Identity: 1.5995\n",
      "[Train] Epoch 13/20 - Batch 120/225, D_face: 0.0009, D_sketch: 0.0037, G: 4.8870, Cycle: 1.8315, Identity: 1.0423\n",
      "[Train] Epoch 13/20 - Batch 130/225, D_face: 0.0009, D_sketch: 0.0084, G: 4.3303, Cycle: 1.4876, Identity: 0.7670\n",
      "[Train] Epoch 13/20 - Batch 140/225, D_face: 0.0015, D_sketch: 0.0043, G: 5.4717, Cycle: 2.3592, Identity: 1.1889\n",
      "[Train] Epoch 13/20 - Batch 150/225, D_face: 0.0012, D_sketch: 0.0030, G: 5.1509, Cycle: 1.9270, Identity: 1.2146\n",
      "[Train] Epoch 13/20 - Batch 160/225, D_face: 0.0032, D_sketch: 0.0049, G: 5.4862, Cycle: 2.4292, Identity: 1.0350\n",
      "[Train] Epoch 13/20 - Batch 170/225, D_face: 0.0015, D_sketch: 0.0045, G: 6.8185, Cycle: 3.4830, Identity: 1.4499\n",
      "[Train] Epoch 13/20 - Batch 180/225, D_face: 0.0012, D_sketch: 0.0046, G: 4.7563, Cycle: 1.8447, Identity: 0.8815\n",
      "[Train] Epoch 13/20 - Batch 190/225, D_face: 0.0011, D_sketch: 0.0038, G: 4.4311, Cycle: 1.5000, Identity: 0.9045\n",
      "[Train] Epoch 13/20 - Batch 200/225, D_face: 0.0016, D_sketch: 0.0061, G: 5.1703, Cycle: 2.0937, Identity: 1.0029\n",
      "[Train] Epoch 13/20 - Batch 210/225, D_face: 0.0009, D_sketch: 0.0071, G: 5.7366, Cycle: 2.5051, Identity: 1.2767\n",
      "[Train] Epoch 13/20 - Batch 220/225, D_face: 0.0011, D_sketch: 0.0086, G: 4.8082, Cycle: 1.8556, Identity: 0.8704\n",
      "[Train] Epoch 13/20 - Batch 225/225, D_face: 0.0005, D_sketch: 0.0078, G: 4.5436, Cycle: 1.6677, Identity: 0.8030\n",
      "[Train] Epoch 13/20, D_face_loss: 0.0016, D_sketch_loss: 0.0055, G_face2sketch_loss: 1.0023, G_sketch2face_loss: 1.0028, cycle_loss: 2.1128, identity_loss: 1.0300, total_G_loss: 5.1479\n",
      "[Validation] Epoch 13/20, D_face_loss: 0.0010, D_sketch_loss: 0.0076, G_face2sketch_loss: 0.9650, G_sketch2face_loss: 0.9861, cycle_loss: 1.9253, identity_loss: 0.9922, total_G_loss: 4.8686\n",
      "Epoch 13 completed in 22.50 seconds\n",
      "[Train] Epoch 14/20 - Batch 10/225, D_face: 0.0054, D_sketch: 0.0030, G: 4.8369, Cycle: 2.0153, Identity: 0.9543\n",
      "[Train] Epoch 14/20 - Batch 20/225, D_face: 0.0012, D_sketch: 0.0057, G: 6.5899, Cycle: 2.9934, Identity: 1.5822\n",
      "[Train] Epoch 14/20 - Batch 30/225, D_face: 0.0007, D_sketch: 0.0040, G: 5.6472, Cycle: 2.6921, Identity: 0.9833\n",
      "[Train] Epoch 14/20 - Batch 40/225, D_face: 0.0010, D_sketch: 0.0057, G: 5.2073, Cycle: 2.1993, Identity: 1.0170\n",
      "[Train] Epoch 14/20 - Batch 50/225, D_face: 0.0009, D_sketch: 0.0065, G: 4.4249, Cycle: 1.6466, Identity: 0.7585\n",
      "[Train] Epoch 14/20 - Batch 60/225, D_face: 0.0009, D_sketch: 0.0032, G: 5.0628, Cycle: 1.9842, Identity: 1.0326\n",
      "[Train] Epoch 14/20 - Batch 70/225, D_face: 0.0005, D_sketch: 0.0039, G: 4.2237, Cycle: 1.5041, Identity: 0.7550\n",
      "[Train] Epoch 14/20 - Batch 80/225, D_face: 0.0319, D_sketch: 0.0025, G: 4.6510, Cycle: 1.8383, Identity: 0.9323\n",
      "[Train] Epoch 14/20 - Batch 90/225, D_face: 0.0025, D_sketch: 0.0030, G: 4.3440, Cycle: 1.5493, Identity: 0.7849\n",
      "[Train] Epoch 14/20 - Batch 100/225, D_face: 0.0028, D_sketch: 0.0023, G: 4.5065, Cycle: 1.5667, Identity: 0.9115\n",
      "[Train] Epoch 14/20 - Batch 110/225, D_face: 0.0036, D_sketch: 0.0028, G: 4.8633, Cycle: 1.8172, Identity: 0.9717\n",
      "[Train] Epoch 14/20 - Batch 120/225, D_face: 0.0025, D_sketch: 0.0019, G: 4.8936, Cycle: 2.0012, Identity: 0.9063\n",
      "[Train] Epoch 14/20 - Batch 130/225, D_face: 0.0021, D_sketch: 0.0028, G: 4.6703, Cycle: 1.9063, Identity: 0.7809\n",
      "[Train] Epoch 14/20 - Batch 140/225, D_face: 0.0028, D_sketch: 0.0047, G: 4.2694, Cycle: 1.5224, Identity: 0.7651\n",
      "[Train] Epoch 14/20 - Batch 150/225, D_face: 0.0030, D_sketch: 0.0037, G: 5.0036, Cycle: 1.7492, Identity: 1.1891\n",
      "[Train] Epoch 14/20 - Batch 160/225, D_face: 0.0012, D_sketch: 0.0038, G: 4.9706, Cycle: 2.0397, Identity: 1.0029\n",
      "[Train] Epoch 14/20 - Batch 170/225, D_face: 0.0008, D_sketch: 0.0084, G: 4.3718, Cycle: 1.5055, Identity: 0.8123\n",
      "[Train] Epoch 14/20 - Batch 180/225, D_face: 0.0013, D_sketch: 0.0033, G: 3.5512, Cycle: 1.0278, Identity: 0.5640\n",
      "[Train] Epoch 14/20 - Batch 190/225, D_face: 0.0012, D_sketch: 0.0030, G: 6.0191, Cycle: 2.7391, Identity: 1.2865\n",
      "[Train] Epoch 14/20 - Batch 200/225, D_face: 0.0014, D_sketch: 0.0021, G: 4.2733, Cycle: 1.5523, Identity: 0.7504\n",
      "[Train] Epoch 14/20 - Batch 210/225, D_face: 0.0039, D_sketch: 0.0059, G: 5.8235, Cycle: 2.6137, Identity: 1.2293\n",
      "[Train] Epoch 14/20 - Batch 220/225, D_face: 0.0015, D_sketch: 0.0034, G: 4.8821, Cycle: 1.8942, Identity: 0.8632\n",
      "[Train] Epoch 14/20 - Batch 225/225, D_face: 0.0020, D_sketch: 0.0065, G: 6.0625, Cycle: 2.6557, Identity: 1.4456\n",
      "[Train] Epoch 14/20, D_face_loss: 0.0068, D_sketch_loss: 0.0042, G_face2sketch_loss: 1.0008, G_sketch2face_loss: 1.0011, cycle_loss: 1.9943, identity_loss: 0.9869, total_G_loss: 4.9832\n",
      "[Validation] Epoch 14/20, D_face_loss: 0.0013, D_sketch_loss: 0.0068, G_face2sketch_loss: 1.0139, G_sketch2face_loss: 0.9865, cycle_loss: 2.1222, identity_loss: 1.0264, total_G_loss: 5.1490\n",
      "Epoch 14 completed in 22.36 seconds\n",
      "[Train] Epoch 15/20 - Batch 10/225, D_face: 0.0008, D_sketch: 0.0036, G: 4.6115, Cycle: 1.6074, Identity: 0.9265\n",
      "[Train] Epoch 15/20 - Batch 20/225, D_face: 0.0012, D_sketch: 0.0138, G: 5.7325, Cycle: 2.5566, Identity: 1.2088\n",
      "[Train] Epoch 15/20 - Batch 30/225, D_face: 0.0005, D_sketch: 0.0068, G: 4.3260, Cycle: 1.5779, Identity: 0.7892\n",
      "[Train] Epoch 15/20 - Batch 40/225, D_face: 0.0010, D_sketch: 0.0025, G: 4.3060, Cycle: 1.5042, Identity: 0.8214\n",
      "[Train] Epoch 15/20 - Batch 50/225, D_face: 0.0056, D_sketch: 0.0104, G: 6.2672, Cycle: 2.9684, Identity: 1.3389\n",
      "[Train] Epoch 15/20 - Batch 60/225, D_face: 0.0015, D_sketch: 0.0030, G: 4.2344, Cycle: 1.4276, Identity: 0.7643\n",
      "[Train] Epoch 15/20 - Batch 70/225, D_face: 0.0023, D_sketch: 0.0043, G: 6.8350, Cycle: 3.3699, Identity: 1.5576\n",
      "[Train] Epoch 15/20 - Batch 80/225, D_face: 0.0006, D_sketch: 0.0036, G: 3.6047, Cycle: 1.0092, Identity: 0.5575\n",
      "[Train] Epoch 15/20 - Batch 90/225, D_face: 0.0007, D_sketch: 0.0032, G: 5.4410, Cycle: 2.4365, Identity: 1.0209\n",
      "[Train] Epoch 15/20 - Batch 100/225, D_face: 0.0013, D_sketch: 0.0042, G: 5.1966, Cycle: 2.2365, Identity: 0.9150\n",
      "[Train] Epoch 15/20 - Batch 110/225, D_face: 0.0015, D_sketch: 0.0106, G: 4.7266, Cycle: 2.0831, Identity: 0.7587\n",
      "[Train] Epoch 15/20 - Batch 120/225, D_face: 0.0010, D_sketch: 0.0128, G: 4.5807, Cycle: 1.7082, Identity: 0.8283\n",
      "[Train] Epoch 15/20 - Batch 130/225, D_face: 0.0010, D_sketch: 0.0029, G: 5.4061, Cycle: 2.3444, Identity: 1.0731\n",
      "[Train] Epoch 15/20 - Batch 140/225, D_face: 0.0005, D_sketch: 0.0067, G: 4.7202, Cycle: 1.8711, Identity: 0.8571\n",
      "[Train] Epoch 15/20 - Batch 150/225, D_face: 0.0007, D_sketch: 0.0023, G: 4.3456, Cycle: 1.5067, Identity: 0.8607\n",
      "[Train] Epoch 15/20 - Batch 160/225, D_face: 0.0005, D_sketch: 0.0020, G: 4.5046, Cycle: 1.5801, Identity: 0.8917\n",
      "[Train] Epoch 15/20 - Batch 170/225, D_face: 0.0007, D_sketch: 0.0052, G: 4.3748, Cycle: 1.5467, Identity: 0.8228\n",
      "[Train] Epoch 15/20 - Batch 180/225, D_face: 0.0012, D_sketch: 0.0109, G: 5.5774, Cycle: 2.3440, Identity: 1.2777\n",
      "[Train] Epoch 15/20 - Batch 190/225, D_face: 0.0007, D_sketch: 0.0062, G: 4.1036, Cycle: 1.3863, Identity: 0.7120\n",
      "[Train] Epoch 15/20 - Batch 200/225, D_face: 0.0006, D_sketch: 0.0037, G: 5.2684, Cycle: 2.1002, Identity: 1.1188\n",
      "[Train] Epoch 15/20 - Batch 210/225, D_face: 0.0011, D_sketch: 0.0094, G: 5.7262, Cycle: 2.4052, Identity: 1.3246\n",
      "[Train] Epoch 15/20 - Batch 220/225, D_face: 0.0015, D_sketch: 0.0032, G: 4.7979, Cycle: 1.9221, Identity: 0.9341\n",
      "[Train] Epoch 15/20 - Batch 225/225, D_face: 0.0008, D_sketch: 0.0068, G: 4.4515, Cycle: 1.6609, Identity: 0.8092\n",
      "[Train] Epoch 15/20, D_face_loss: 0.0012, D_sketch_loss: 0.0063, G_face2sketch_loss: 1.0041, G_sketch2face_loss: 1.0005, cycle_loss: 1.9788, identity_loss: 0.9498, total_G_loss: 4.9331\n",
      "[Validation] Epoch 15/20, D_face_loss: 0.0011, D_sketch_loss: 0.0060, G_face2sketch_loss: 1.0371, G_sketch2face_loss: 0.9828, cycle_loss: 1.9896, identity_loss: 0.9104, total_G_loss: 4.9199\n",
      "Epoch 15 completed in 23.58 seconds\n",
      "[Train] Epoch 16/20 - Batch 10/225, D_face: 0.0007, D_sketch: 0.0070, G: 4.3139, Cycle: 1.4561, Identity: 0.8490\n",
      "[Train] Epoch 16/20 - Batch 20/225, D_face: 0.0005, D_sketch: 0.0034, G: 5.2557, Cycle: 2.1322, Identity: 1.1414\n",
      "[Train] Epoch 16/20 - Batch 30/225, D_face: 0.0010, D_sketch: 0.0012, G: 3.8861, Cycle: 1.2032, Identity: 0.6352\n",
      "[Train] Epoch 16/20 - Batch 40/225, D_face: 0.0007, D_sketch: 0.0096, G: 4.3347, Cycle: 1.3913, Identity: 0.8124\n",
      "[Train] Epoch 16/20 - Batch 50/225, D_face: 0.0007, D_sketch: 0.0021, G: 3.6033, Cycle: 1.1244, Identity: 0.4839\n",
      "[Train] Epoch 16/20 - Batch 60/225, D_face: 0.0006, D_sketch: 0.0030, G: 4.5240, Cycle: 1.7004, Identity: 0.7748\n",
      "[Train] Epoch 16/20 - Batch 70/225, D_face: 0.0006, D_sketch: 0.0030, G: 4.3659, Cycle: 1.6208, Identity: 0.7872\n",
      "[Train] Epoch 16/20 - Batch 80/225, D_face: 0.0013, D_sketch: 0.0052, G: 4.0665, Cycle: 1.3928, Identity: 0.7181\n",
      "[Train] Epoch 16/20 - Batch 90/225, D_face: 0.0006, D_sketch: 0.0035, G: 4.2167, Cycle: 1.5782, Identity: 0.7078\n",
      "[Train] Epoch 16/20 - Batch 100/225, D_face: 0.0006, D_sketch: 0.0045, G: 5.6449, Cycle: 2.5288, Identity: 1.1013\n",
      "[Train] Epoch 16/20 - Batch 110/225, D_face: 0.0004, D_sketch: 0.0069, G: 3.6378, Cycle: 1.1331, Identity: 0.5410\n",
      "[Train] Epoch 16/20 - Batch 120/225, D_face: 0.0009, D_sketch: 0.0111, G: 3.7826, Cycle: 1.1230, Identity: 0.5975\n",
      "[Train] Epoch 16/20 - Batch 130/225, D_face: 0.0011, D_sketch: 0.0039, G: 4.6374, Cycle: 1.7228, Identity: 0.9125\n",
      "[Train] Epoch 16/20 - Batch 140/225, D_face: 0.0022, D_sketch: 0.0025, G: 4.1936, Cycle: 1.5625, Identity: 0.6389\n",
      "[Train] Epoch 16/20 - Batch 150/225, D_face: 0.0015, D_sketch: 0.0045, G: 4.8012, Cycle: 1.9095, Identity: 0.9328\n",
      "[Train] Epoch 16/20 - Batch 160/225, D_face: 0.0737, D_sketch: 0.0036, G: 9.7085, Cycle: 5.7523, Identity: 2.5582\n",
      "[Train] Epoch 16/20 - Batch 170/225, D_face: 0.0058, D_sketch: 0.0071, G: 5.7157, Cycle: 2.4592, Identity: 1.1956\n",
      "[Train] Epoch 16/20 - Batch 180/225, D_face: 0.0108, D_sketch: 0.0067, G: 6.0865, Cycle: 2.5225, Identity: 1.5194\n",
      "[Train] Epoch 16/20 - Batch 190/225, D_face: 0.0055, D_sketch: 0.0023, G: 5.2232, Cycle: 2.1568, Identity: 1.1816\n",
      "[Train] Epoch 16/20 - Batch 200/225, D_face: 0.0066, D_sketch: 0.0087, G: 5.8312, Cycle: 2.5252, Identity: 1.4135\n",
      "[Train] Epoch 16/20 - Batch 210/225, D_face: 0.0017, D_sketch: 0.0133, G: 5.5339, Cycle: 2.5439, Identity: 1.0157\n",
      "[Train] Epoch 16/20 - Batch 220/225, D_face: 0.0016, D_sketch: 0.0028, G: 5.5786, Cycle: 2.6342, Identity: 0.9930\n",
      "[Train] Epoch 16/20 - Batch 225/225, D_face: 0.0091, D_sketch: 0.0074, G: 5.2820, Cycle: 2.2002, Identity: 1.1654\n",
      "[Train] Epoch 16/20, D_face_loss: 0.0042, D_sketch_loss: 0.0049, G_face2sketch_loss: 1.0013, G_sketch2face_loss: 1.0034, cycle_loss: 1.9666, identity_loss: 0.9435, total_G_loss: 4.9149\n",
      "[Validation] Epoch 16/20, D_face_loss: 0.0033, D_sketch_loss: 0.0039, G_face2sketch_loss: 1.0480, G_sketch2face_loss: 1.0420, cycle_loss: 1.8796, identity_loss: 0.9286, total_G_loss: 4.8981\n",
      "Epoch 16 completed in 22.56 seconds\n",
      "[Train] Epoch 17/20 - Batch 10/225, D_face: 0.0021, D_sketch: 0.0084, G: 4.0555, Cycle: 1.3711, Identity: 0.7092\n",
      "[Train] Epoch 17/20 - Batch 20/225, D_face: 0.0012, D_sketch: 0.0029, G: 3.8284, Cycle: 1.2384, Identity: 0.5897\n",
      "[Train] Epoch 17/20 - Batch 30/225, D_face: 0.0020, D_sketch: 0.0024, G: 5.2078, Cycle: 2.2686, Identity: 0.9451\n",
      "[Train] Epoch 17/20 - Batch 40/225, D_face: 0.0017, D_sketch: 0.0048, G: 5.9536, Cycle: 2.8238, Identity: 1.2562\n",
      "[Train] Epoch 17/20 - Batch 50/225, D_face: 0.0009, D_sketch: 0.0107, G: 4.6754, Cycle: 1.6424, Identity: 0.8882\n",
      "[Train] Epoch 17/20 - Batch 60/225, D_face: 0.0021, D_sketch: 0.0030, G: 6.2656, Cycle: 2.7902, Identity: 1.4661\n",
      "[Train] Epoch 17/20 - Batch 70/225, D_face: 0.0015, D_sketch: 0.0041, G: 4.8115, Cycle: 1.8141, Identity: 1.0630\n",
      "[Train] Epoch 17/20 - Batch 80/225, D_face: 0.0176, D_sketch: 0.0022, G: 4.6883, Cycle: 1.7292, Identity: 0.9138\n",
      "[Train] Epoch 17/20 - Batch 90/225, D_face: 0.0022, D_sketch: 0.0064, G: 4.4535, Cycle: 1.5791, Identity: 0.8344\n",
      "[Train] Epoch 17/20 - Batch 100/225, D_face: 0.0013, D_sketch: 0.0030, G: 4.2540, Cycle: 1.4390, Identity: 0.8016\n",
      "[Train] Epoch 17/20 - Batch 110/225, D_face: 0.0012, D_sketch: 0.0021, G: 3.7951, Cycle: 1.1389, Identity: 0.6121\n",
      "[Train] Epoch 17/20 - Batch 120/225, D_face: 0.0010, D_sketch: 0.0132, G: 5.1471, Cycle: 2.1169, Identity: 1.0210\n",
      "[Train] Epoch 17/20 - Batch 130/225, D_face: 0.0008, D_sketch: 0.0020, G: 6.4719, Cycle: 3.2136, Identity: 1.2524\n",
      "[Train] Epoch 17/20 - Batch 140/225, D_face: 0.0011, D_sketch: 0.0034, G: 4.6863, Cycle: 1.7337, Identity: 0.8963\n",
      "[Train] Epoch 17/20 - Batch 150/225, D_face: 0.0005, D_sketch: 0.0019, G: 6.1333, Cycle: 2.7544, Identity: 1.3876\n",
      "[Train] Epoch 17/20 - Batch 160/225, D_face: 0.0010, D_sketch: 0.0033, G: 4.9045, Cycle: 1.9804, Identity: 0.9727\n",
      "[Train] Epoch 17/20 - Batch 170/225, D_face: 0.0012, D_sketch: 0.0079, G: 4.4380, Cycle: 1.5149, Identity: 0.8419\n",
      "[Train] Epoch 17/20 - Batch 180/225, D_face: 0.0013, D_sketch: 0.0070, G: 6.1079, Cycle: 2.7650, Identity: 1.3166\n",
      "[Train] Epoch 17/20 - Batch 190/225, D_face: 0.0010, D_sketch: 0.0130, G: 4.2793, Cycle: 1.4926, Identity: 0.7961\n",
      "[Train] Epoch 17/20 - Batch 200/225, D_face: 0.0006, D_sketch: 0.0029, G: 5.6362, Cycle: 2.5086, Identity: 1.1444\n",
      "[Train] Epoch 17/20 - Batch 210/225, D_face: 0.0067, D_sketch: 0.0048, G: 4.6869, Cycle: 1.7317, Identity: 0.9092\n",
      "[Train] Epoch 17/20 - Batch 220/225, D_face: 0.0016, D_sketch: 0.0031, G: 4.3088, Cycle: 1.5693, Identity: 0.6892\n",
      "[Train] Epoch 17/20 - Batch 225/225, D_face: 0.0016, D_sketch: 0.0058, G: 3.7753, Cycle: 1.0894, Identity: 0.6282\n",
      "[Train] Epoch 17/20, D_face_loss: 0.0033, D_sketch_loss: 0.0042, G_face2sketch_loss: 1.0011, G_sketch2face_loss: 1.0020, cycle_loss: 1.9616, identity_loss: 0.9352, total_G_loss: 4.8998\n",
      "[Validation] Epoch 17/20, D_face_loss: 0.0016, D_sketch_loss: 0.0073, G_face2sketch_loss: 0.9879, G_sketch2face_loss: 1.0160, cycle_loss: 2.0064, identity_loss: 0.8852, total_G_loss: 4.8956\n",
      "Epoch 17 completed in 22.51 seconds\n",
      "[Train] Epoch 18/20 - Batch 10/225, D_face: 0.0012, D_sketch: 0.0051, G: 5.9008, Cycle: 2.7356, Identity: 1.1946\n",
      "[Train] Epoch 18/20 - Batch 20/225, D_face: 0.0007, D_sketch: 0.0034, G: 5.5526, Cycle: 2.4651, Identity: 1.0962\n",
      "[Train] Epoch 18/20 - Batch 30/225, D_face: 0.0034, D_sketch: 0.0030, G: 4.3478, Cycle: 1.4853, Identity: 0.7961\n",
      "[Train] Epoch 18/20 - Batch 40/225, D_face: 0.0017, D_sketch: 0.0036, G: 6.6409, Cycle: 3.3344, Identity: 1.3236\n",
      "[Train] Epoch 18/20 - Batch 50/225, D_face: 0.0008, D_sketch: 0.0037, G: 4.2487, Cycle: 1.5313, Identity: 0.7235\n",
      "[Train] Epoch 18/20 - Batch 60/225, D_face: 0.0008, D_sketch: 0.0130, G: 4.5290, Cycle: 1.7155, Identity: 0.8966\n",
      "[Train] Epoch 18/20 - Batch 70/225, D_face: 0.0012, D_sketch: 0.0030, G: 5.6701, Cycle: 2.5808, Identity: 1.0456\n",
      "[Train] Epoch 18/20 - Batch 80/225, D_face: 0.0083, D_sketch: 0.0032, G: 4.9249, Cycle: 2.0013, Identity: 0.9461\n",
      "[Train] Epoch 18/20 - Batch 90/225, D_face: 0.0013, D_sketch: 0.0020, G: 5.1460, Cycle: 2.1732, Identity: 0.9599\n",
      "[Train] Epoch 18/20 - Batch 100/225, D_face: 0.0004, D_sketch: 0.0029, G: 3.9018, Cycle: 1.2377, Identity: 0.6294\n",
      "[Train] Epoch 18/20 - Batch 110/225, D_face: 0.0009, D_sketch: 0.0110, G: 5.4231, Cycle: 2.4953, Identity: 1.0061\n",
      "[Train] Epoch 18/20 - Batch 120/225, D_face: 0.0020, D_sketch: 0.0038, G: 5.0106, Cycle: 2.0541, Identity: 0.9560\n",
      "[Train] Epoch 18/20 - Batch 130/225, D_face: 0.0014, D_sketch: 0.0045, G: 5.0226, Cycle: 2.0347, Identity: 0.9353\n",
      "[Train] Epoch 18/20 - Batch 140/225, D_face: 0.0006, D_sketch: 0.0040, G: 4.8582, Cycle: 1.8065, Identity: 1.0123\n",
      "[Train] Epoch 18/20 - Batch 150/225, D_face: 0.0003, D_sketch: 0.0040, G: 4.7839, Cycle: 1.7812, Identity: 1.0219\n",
      "[Train] Epoch 18/20 - Batch 160/225, D_face: 0.0005, D_sketch: 0.0044, G: 4.4856, Cycle: 1.6431, Identity: 0.8803\n",
      "[Train] Epoch 18/20 - Batch 170/225, D_face: 0.0008, D_sketch: 0.0021, G: 5.3597, Cycle: 2.2418, Identity: 1.1667\n",
      "[Train] Epoch 18/20 - Batch 180/225, D_face: 0.0060, D_sketch: 0.0062, G: 3.7899, Cycle: 1.2390, Identity: 0.6478\n",
      "[Train] Epoch 18/20 - Batch 190/225, D_face: 0.0035, D_sketch: 0.0053, G: 4.1659, Cycle: 1.5273, Identity: 0.7634\n",
      "[Train] Epoch 18/20 - Batch 200/225, D_face: 0.0028, D_sketch: 0.0119, G: 5.1579, Cycle: 2.1875, Identity: 1.0533\n",
      "[Train] Epoch 18/20 - Batch 210/225, D_face: 0.0016, D_sketch: 0.0031, G: 5.6192, Cycle: 2.4170, Identity: 1.1979\n",
      "[Train] Epoch 18/20 - Batch 220/225, D_face: 0.0043, D_sketch: 0.0014, G: 4.6875, Cycle: 1.8094, Identity: 0.8882\n",
      "[Train] Epoch 18/20 - Batch 225/225, D_face: 0.0005, D_sketch: 0.0054, G: 3.8268, Cycle: 1.3170, Identity: 0.5668\n",
      "[Train] Epoch 18/20, D_face_loss: 0.0014, D_sketch_loss: 0.0059, G_face2sketch_loss: 1.0012, G_sketch2face_loss: 1.0018, cycle_loss: 1.9085, identity_loss: 0.9015, total_G_loss: 4.8130\n",
      "[Validation] Epoch 18/20, D_face_loss: 0.0008, D_sketch_loss: 0.0044, G_face2sketch_loss: 1.0593, G_sketch2face_loss: 0.9807, cycle_loss: 1.9679, identity_loss: 0.8682, total_G_loss: 4.8761\n",
      "Epoch 18 completed in 22.56 seconds\n",
      "[Train] Epoch 19/20 - Batch 10/225, D_face: 0.0011, D_sketch: 0.0140, G: 5.7724, Cycle: 2.6626, Identity: 1.0899\n",
      "[Train] Epoch 19/20 - Batch 20/225, D_face: 0.5441, D_sketch: 0.1273, G: 14.3083, Cycle: 7.2760, Identity: 6.2204\n",
      "[Train] Epoch 19/20 - Batch 30/225, D_face: 0.0330, D_sketch: 0.0137, G: 14.0679, Cycle: 8.3579, Identity: 4.0209\n",
      "[Train] Epoch 19/20 - Batch 40/225, D_face: 0.0385, D_sketch: 0.0157, G: 10.3357, Cycle: 5.4789, Identity: 2.9648\n",
      "[Train] Epoch 19/20 - Batch 50/225, D_face: 0.0131, D_sketch: 0.0159, G: 7.1453, Cycle: 3.5674, Identity: 1.6585\n",
      "[Train] Epoch 19/20 - Batch 60/225, D_face: 0.0304, D_sketch: 0.1056, G: 6.9271, Cycle: 3.4672, Identity: 1.4995\n",
      "[Train] Epoch 19/20 - Batch 70/225, D_face: 0.0539, D_sketch: 0.0265, G: 6.7457, Cycle: 3.1659, Identity: 1.6401\n",
      "[Train] Epoch 19/20 - Batch 80/225, D_face: 0.0052, D_sketch: 0.0206, G: 6.3567, Cycle: 2.8647, Identity: 1.5540\n",
      "[Train] Epoch 19/20 - Batch 90/225, D_face: 0.0022, D_sketch: 0.0091, G: 5.7777, Cycle: 2.2232, Identity: 1.3178\n",
      "[Train] Epoch 19/20 - Batch 100/225, D_face: 0.0019, D_sketch: 0.0055, G: 6.2831, Cycle: 2.8955, Identity: 1.4317\n",
      "[Train] Epoch 19/20 - Batch 110/225, D_face: 0.0018, D_sketch: 0.0718, G: 7.3773, Cycle: 3.2378, Identity: 1.5588\n",
      "[Train] Epoch 19/20 - Batch 120/225, D_face: 0.0045, D_sketch: 0.0068, G: 4.5415, Cycle: 1.6101, Identity: 0.8416\n",
      "[Train] Epoch 19/20 - Batch 130/225, D_face: 0.0024, D_sketch: 0.0162, G: 11.2011, Cycle: 5.9359, Identity: 4.1906\n",
      "[Train] Epoch 19/20 - Batch 140/225, D_face: 0.0017, D_sketch: 0.0056, G: 4.8541, Cycle: 1.9420, Identity: 1.0674\n",
      "[Train] Epoch 19/20 - Batch 150/225, D_face: 0.0094, D_sketch: 0.0059, G: 5.5679, Cycle: 2.3487, Identity: 1.2205\n",
      "[Train] Epoch 19/20 - Batch 160/225, D_face: 0.0015, D_sketch: 0.0050, G: 6.1352, Cycle: 2.7509, Identity: 1.3414\n",
      "[Train] Epoch 19/20 - Batch 170/225, D_face: 0.0023, D_sketch: 0.3250, G: 6.3464, Cycle: 3.2636, Identity: 1.0707\n",
      "[Train] Epoch 19/20 - Batch 180/225, D_face: 0.0010, D_sketch: 0.0199, G: 4.8986, Cycle: 2.0467, Identity: 0.8474\n",
      "[Train] Epoch 19/20 - Batch 190/225, D_face: 0.0010, D_sketch: 0.0166, G: 5.4931, Cycle: 2.1893, Identity: 1.1230\n",
      "[Train] Epoch 19/20 - Batch 200/225, D_face: 0.0019, D_sketch: 0.0044, G: 4.8519, Cycle: 1.8506, Identity: 0.9863\n",
      "[Train] Epoch 19/20 - Batch 210/225, D_face: 0.0006, D_sketch: 0.0077, G: 4.4848, Cycle: 1.4928, Identity: 0.8849\n",
      "[Train] Epoch 19/20 - Batch 220/225, D_face: 0.0013, D_sketch: 0.0066, G: 4.7861, Cycle: 1.9998, Identity: 0.8213\n",
      "[Train] Epoch 19/20 - Batch 225/225, D_face: 0.0007, D_sketch: 0.0090, G: 4.2512, Cycle: 1.6099, Identity: 0.6828\n",
      "[Train] Epoch 19/20, D_face_loss: 0.0278, D_sketch_loss: 0.0296, G_face2sketch_loss: 0.9810, G_sketch2face_loss: 0.9858, cycle_loss: 3.1736, identity_loss: 1.6833, total_G_loss: 6.8237\n",
      "[Validation] Epoch 19/20, D_face_loss: 0.0190, D_sketch_loss: 0.0155, G_face2sketch_loss: 0.9571, G_sketch2face_loss: 0.9413, cycle_loss: 2.5136, identity_loss: 1.2807, total_G_loss: 5.6928\n",
      "Epoch 19 completed in 22.27 seconds\n",
      "[Train] Epoch 20/20 - Batch 10/225, D_face: 0.0017, D_sketch: 0.0114, G: 6.0914, Cycle: 2.5460, Identity: 1.6626\n",
      "[Train] Epoch 20/20 - Batch 20/225, D_face: 0.0008, D_sketch: 0.0115, G: 6.4498, Cycle: 3.1893, Identity: 1.2189\n",
      "[Train] Epoch 20/20 - Batch 30/225, D_face: 0.0011, D_sketch: 0.0097, G: 5.4625, Cycle: 2.3044, Identity: 1.1726\n",
      "[Train] Epoch 20/20 - Batch 40/225, D_face: 0.0013, D_sketch: 0.0048, G: 6.0864, Cycle: 2.7554, Identity: 1.2704\n",
      "[Train] Epoch 20/20 - Batch 50/225, D_face: 0.0010, D_sketch: 0.0023, G: 4.3463, Cycle: 1.5027, Identity: 0.8395\n",
      "[Train] Epoch 20/20 - Batch 60/225, D_face: 0.0005, D_sketch: 0.0064, G: 4.2097, Cycle: 1.5426, Identity: 0.6823\n",
      "[Train] Epoch 20/20 - Batch 70/225, D_face: 0.0010, D_sketch: 0.0021, G: 4.0152, Cycle: 1.4374, Identity: 0.6137\n",
      "[Train] Epoch 20/20 - Batch 80/225, D_face: 0.0007, D_sketch: 0.0022, G: 4.4607, Cycle: 1.6488, Identity: 0.7796\n",
      "[Train] Epoch 20/20 - Batch 90/225, D_face: 0.0019, D_sketch: 0.0109, G: 6.9027, Cycle: 3.5684, Identity: 1.3571\n",
      "[Train] Epoch 20/20 - Batch 100/225, D_face: 0.0013, D_sketch: 0.0012, G: 5.4213, Cycle: 2.4247, Identity: 1.0555\n",
      "[Train] Epoch 20/20 - Batch 110/225, D_face: 0.0013, D_sketch: 0.0052, G: 3.6272, Cycle: 1.0417, Identity: 0.6369\n",
      "[Train] Epoch 20/20 - Batch 120/225, D_face: 0.0003, D_sketch: 0.0039, G: 4.8945, Cycle: 2.0149, Identity: 0.8054\n",
      "[Train] Epoch 20/20 - Batch 130/225, D_face: 0.0005, D_sketch: 0.0021, G: 4.1532, Cycle: 1.3862, Identity: 0.7310\n",
      "[Train] Epoch 20/20 - Batch 140/225, D_face: 0.0004, D_sketch: 0.0030, G: 4.3915, Cycle: 1.6408, Identity: 0.7738\n",
      "[Train] Epoch 20/20 - Batch 150/225, D_face: 0.0012, D_sketch: 0.0015, G: 5.6193, Cycle: 2.5540, Identity: 1.1201\n",
      "[Train] Epoch 20/20 - Batch 160/225, D_face: 0.0005, D_sketch: 0.0027, G: 3.9471, Cycle: 1.3226, Identity: 0.5947\n",
      "[Train] Epoch 20/20 - Batch 170/225, D_face: 0.0011, D_sketch: 0.0039, G: 4.8551, Cycle: 1.9576, Identity: 0.9644\n",
      "[Train] Epoch 20/20 - Batch 180/225, D_face: 0.0014, D_sketch: 0.0021, G: 4.9433, Cycle: 1.9952, Identity: 0.9460\n",
      "[Train] Epoch 20/20 - Batch 190/225, D_face: 0.0006, D_sketch: 0.0036, G: 4.4930, Cycle: 1.6644, Identity: 0.8669\n",
      "[Train] Epoch 20/20 - Batch 200/225, D_face: 0.0002, D_sketch: 0.0019, G: 3.6080, Cycle: 1.0023, Identity: 0.5902\n",
      "[Train] Epoch 20/20 - Batch 210/225, D_face: 0.0007, D_sketch: 0.0020, G: 4.3790, Cycle: 1.6020, Identity: 0.7713\n",
      "[Train] Epoch 20/20 - Batch 220/225, D_face: 0.0015, D_sketch: 0.0020, G: 5.1220, Cycle: 2.0429, Identity: 1.0472\n",
      "[Train] Epoch 20/20 - Batch 225/225, D_face: 0.0003, D_sketch: 0.0021, G: 4.2625, Cycle: 1.4959, Identity: 0.7619\n",
      "[Train] Epoch 20/20, D_face_loss: 0.0010, D_sketch_loss: 0.0052, G_face2sketch_loss: 0.9963, G_sketch2face_loss: 1.0027, cycle_loss: 2.1609, identity_loss: 1.0253, total_G_loss: 5.1851\n",
      "[Validation] Epoch 20/20, D_face_loss: 0.0020, D_sketch_loss: 0.0026, G_face2sketch_loss: 0.9976, G_sketch2face_loss: 0.9910, cycle_loss: 1.9340, identity_loss: 0.9354, total_G_loss: 4.8580\n",
      "Epoch 20 completed in 23.90 seconds\n",
      "Testing the model...\n",
      "Training and testing completed successfully!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "import glob\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import gc\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "# Memory optimization settings\n",
    "torch.cuda.empty_cache()\n",
    "os.environ['PYTORCH_CUDA_ALLOC_CONF'] = 'expandable_segments:True'\n",
    "\n",
    "# Check if CUDA is available and select device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Define constants - reduced for memory efficiency\n",
    "BATCH_SIZE = 1\n",
    "IMAGE_SIZE = 128\n",
    "CHANNELS = 3\n",
    "EPOCHS = 20\n",
    "LEARNING_RATE = 0.0002\n",
    "BETA1 = 0.5\n",
    "BETA2 = 0.999\n",
    "LAMBDA_CYCLE = 10\n",
    "LAMBDA_IDENTITY = 0.5 * LAMBDA_CYCLE\n",
    "NUM_RESIDUAL_BLOCKS = 6  # Reduced from 9\n",
    "\n",
    "# Define paths\n",
    "dataset_path = '/kaggle/input/person-face-sketches'\n",
    "CHECKPOINT_DIR = './checkpoints'\n",
    "RESULT_DIR = './results'\n",
    "\n",
    "# Create directories if they don't exist\n",
    "os.makedirs(CHECKPOINT_DIR, exist_ok=True)\n",
    "os.makedirs(RESULT_DIR, exist_ok=True)\n",
    "\n",
    "# ------------------ Dataset Processing ------------------\n",
    "\n",
    "print(\"Finding images in dataset...\")\n",
    "# Find all images\n",
    "image_files = []\n",
    "for ext in ['*.jpg', '*.jpeg', '*.png']:\n",
    "    image_files.extend(glob.glob(os.path.join(dataset_path, '**', ext), recursive=True))\n",
    "\n",
    "print(f\"Found {len(image_files)} image files\")\n",
    "\n",
    "# Try to identify face and sketch directories\n",
    "face_dirs = []\n",
    "sketch_dirs = []\n",
    "all_dirs = set(os.path.dirname(path) for path in image_files)\n",
    "\n",
    "for directory in all_dirs:\n",
    "    dir_lower = directory.lower()\n",
    "    if any(kw in dir_lower for kw in ['face', 'photo', 'real']):\n",
    "        face_dirs.append(directory)\n",
    "    elif any(kw in dir_lower for kw in ['sketch', 'drawing']):\n",
    "        sketch_dirs.append(directory)\n",
    "\n",
    "print(\"\\nPotential face directories:\", face_dirs)\n",
    "print(\"Potential sketch directories:\", sketch_dirs)\n",
    "\n",
    "# Separate face and sketch images\n",
    "face_images = []\n",
    "sketch_images = []\n",
    "\n",
    "# First try directory-based detection\n",
    "if face_dirs and sketch_dirs:\n",
    "    for img_path in image_files:\n",
    "        if any(img_path.startswith(dir) for dir in face_dirs):\n",
    "            face_images.append(img_path)\n",
    "        elif any(img_path.startswith(dir) for dir in sketch_dirs):\n",
    "            sketch_images.append(img_path)\n",
    "else:\n",
    "    # Fall back to filename-based detection\n",
    "    for img_path in image_files:\n",
    "        filename = os.path.basename(img_path).lower()\n",
    "        if any(kw in filename for kw in ['face', 'photo', 'real']):\n",
    "            face_images.append(img_path)\n",
    "        elif any(kw in filename for kw in ['sketch', 'drawing']):\n",
    "            sketch_images.append(img_path)\n",
    "\n",
    "# If still not enough images, try splitting by directory\n",
    "if len(face_images) < 10 or len(sketch_images) < 10:\n",
    "    print(\"\\nCouldn't clearly identify face and sketch images by names. Attempting to split by directories...\")\n",
    "    \n",
    "    all_dirs = list(set(os.path.dirname(path) for path in image_files))\n",
    "    if len(all_dirs) >= 2:\n",
    "        # Sort directories by number of images\n",
    "        dir_counts = [(dir, len(glob.glob(os.path.join(dir, '*')))) for dir in all_dirs]\n",
    "        dir_counts.sort(key=lambda x: x[1], reverse=True)\n",
    "        \n",
    "        # Use the two largest directories\n",
    "        face_dir = dir_counts[0][0]\n",
    "        sketch_dir = dir_counts[1][0]\n",
    "        \n",
    "        face_images = [img for img in image_files if img.startswith(face_dir)]\n",
    "        sketch_images = [img for img in image_files if img.startswith(sketch_dir)]\n",
    "        \n",
    "        print(f\"Using {face_dir} as face directory with {len(face_images)} images\")\n",
    "        print(f\"Using {sketch_dir} as sketch directory with {len(sketch_images)} images\")\n",
    "\n",
    "# Last resort: split alphabetically\n",
    "if len(face_images) < 10 or len(sketch_images) < 10:\n",
    "    print(\"\\nStill couldn't identify enough face and sketch images. Splitting all images alphabetically...\")\n",
    "    all_sorted = sorted(image_files)\n",
    "    midpoint = len(all_sorted) // 2\n",
    "    face_images = all_sorted[:midpoint]\n",
    "    sketch_images = all_sorted[midpoint:]\n",
    "\n",
    "print(f\"\\nFinal count: {len(face_images)} face images and {len(sketch_images)} sketch images\")\n",
    "\n",
    "# Limit dataset size to save memory\n",
    "max_images = 250\n",
    "min_count = min(len(face_images), len(sketch_images), max_images)\n",
    "face_images = face_images[:min_count]\n",
    "sketch_images = sketch_images[:min_count]\n",
    "\n",
    "print(f\"Using {len(face_images)} matched pairs for training\")\n",
    "\n",
    "# ------------------ Dataset Class ------------------\n",
    "\n",
    "class FaceSketchDataset(Dataset):\n",
    "    def __init__(self, face_paths, sketch_paths, transform=None):\n",
    "        self.face_paths = face_paths\n",
    "        self.sketch_paths = sketch_paths\n",
    "        self.transform = transform\n",
    "        \n",
    "        assert len(self.face_paths) == len(self.sketch_paths), \"Number of face and sketch images must be equal\"\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.face_paths)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        face_path = self.face_paths[index]\n",
    "        sketch_path = self.sketch_paths[index]\n",
    "        \n",
    "        try:\n",
    "            face_img = Image.open(face_path).convert('RGB')\n",
    "            sketch_img = Image.open(sketch_path).convert('RGB')\n",
    "            \n",
    "            if self.transform:\n",
    "                face_img = self.transform(face_img)\n",
    "                sketch_img = self.transform(sketch_img)\n",
    "            \n",
    "            return {'face': face_img, 'sketch': sketch_img}\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading images: {e}\")\n",
    "            print(f\"Face path: {face_path}\")\n",
    "            print(f\"Sketch path: {sketch_path}\")\n",
    "            # Return placeholder\n",
    "            placeholder = torch.zeros(3, IMAGE_SIZE, IMAGE_SIZE)\n",
    "            return {'face': placeholder, 'sketch': placeholder}\n",
    "\n",
    "# Define image transforms\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((IMAGE_SIZE, IMAGE_SIZE)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "])\n",
    "\n",
    "# Create dataset\n",
    "dataset = FaceSketchDataset(face_images, sketch_images, transform=transform)\n",
    "\n",
    "# Split dataset\n",
    "train_size = int(0.9 * len(dataset))\n",
    "val_size = len(dataset) - train_size\n",
    "\n",
    "if train_size <= 0 or val_size <= 0:\n",
    "    raise ValueError(f\"Dataset too small to split: {len(dataset)} samples\")\n",
    "\n",
    "train_dataset, val_dataset = torch.utils.data.random_split(dataset, [train_size, val_size])\n",
    "\n",
    "# Create dataloaders with low num_workers for memory efficiency\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=0)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=0)\n",
    "\n",
    "print(f\"Train dataloader: {len(train_dataloader)} batches\")\n",
    "print(f\"Validation dataloader: {len(val_dataloader)} batches\")\n",
    "\n",
    "# ------------------ Model Architecture ------------------\n",
    "\n",
    "# Residual block for the generator\n",
    "class ResidualBlock(nn.Module):\n",
    "    def __init__(self, features):\n",
    "        super(ResidualBlock, self).__init__()\n",
    "        \n",
    "        self.block = nn.Sequential(\n",
    "            nn.ReflectionPad2d(1),\n",
    "            nn.Conv2d(features, features, 3),\n",
    "            nn.InstanceNorm2d(features),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.ReflectionPad2d(1),\n",
    "            nn.Conv2d(features, features, 3),\n",
    "            nn.InstanceNorm2d(features)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return x + self.block(x)\n",
    "\n",
    "# Generator architecture\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self, input_channels=3, output_channels=3, n_residual_blocks=NUM_RESIDUAL_BLOCKS, base_filters=32):\n",
    "        super(Generator, self).__init__()\n",
    "        \n",
    "        # Initial convolution\n",
    "        self.initial = nn.Sequential(\n",
    "            nn.ReflectionPad2d(3),\n",
    "            nn.Conv2d(input_channels, base_filters, 7),\n",
    "            nn.InstanceNorm2d(base_filters),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "        \n",
    "        # Downsampling\n",
    "        self.down_sampling = nn.Sequential(\n",
    "            nn.Conv2d(base_filters, base_filters*2, 3, stride=2, padding=1),\n",
    "            nn.InstanceNorm2d(base_filters*2),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(base_filters*2, base_filters*4, 3, stride=2, padding=1),\n",
    "            nn.InstanceNorm2d(base_filters*4),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "        \n",
    "        # Residual blocks\n",
    "        self.residual_blocks = nn.Sequential(\n",
    "            *[ResidualBlock(base_filters*4) for _ in range(n_residual_blocks)]\n",
    "        )\n",
    "        \n",
    "        # Upsampling\n",
    "        self.up_sampling = nn.Sequential(\n",
    "            nn.ConvTranspose2d(base_filters*4, base_filters*2, 3, stride=2, padding=1, output_padding=1),\n",
    "            nn.InstanceNorm2d(base_filters*2),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.ConvTranspose2d(base_filters*2, base_filters, 3, stride=2, padding=1, output_padding=1),\n",
    "            nn.InstanceNorm2d(base_filters),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "        \n",
    "        # Output layer\n",
    "        self.output = nn.Sequential(\n",
    "            nn.ReflectionPad2d(3),\n",
    "            nn.Conv2d(base_filters, output_channels, 7),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.initial(x)\n",
    "        x = self.down_sampling(x)\n",
    "        x = self.residual_blocks(x)\n",
    "        x = self.up_sampling(x)\n",
    "        x = self.output(x)\n",
    "        return x\n",
    "\n",
    "# Discriminator architecture - Fixed to ensure consistent output size\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, input_channels=3, base_filters=32, output_size=16):\n",
    "        super(Discriminator, self).__init__()\n",
    "        \n",
    "        # Force a specific output size for the discriminator\n",
    "        self.output_size = output_size\n",
    "        \n",
    "        # A series of convolutional layers\n",
    "        self.model = nn.Sequential(\n",
    "            # No normalization in the first layer\n",
    "            nn.Conv2d(input_channels, base_filters, 4, stride=2, padding=1),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            \n",
    "            nn.Conv2d(base_filters, base_filters*2, 4, stride=2, padding=1),\n",
    "            nn.InstanceNorm2d(base_filters*2),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            \n",
    "            nn.Conv2d(base_filters*2, base_filters*4, 4, stride=2, padding=1),\n",
    "            nn.InstanceNorm2d(base_filters*4),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            \n",
    "            nn.Conv2d(base_filters*4, base_filters*8, 4, padding=1),\n",
    "            nn.InstanceNorm2d(base_filters*8),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            \n",
    "            # Output 1-channel prediction map\n",
    "            nn.Conv2d(base_filters*8, 1, 4, padding=1)\n",
    "        )\n",
    "        \n",
    "        # Adaptive pooling to ensure consistent output size\n",
    "        self.adaptive_pool = nn.AdaptiveAvgPool2d((output_size, output_size))\n",
    "    \n",
    "    def forward(self, x):\n",
    "        features = self.model(x)\n",
    "        # Ensure consistent output size\n",
    "        return self.adaptive_pool(features)\n",
    "\n",
    "# Initialize generators and discriminators\n",
    "# Ensure consistent output size for discriminators\n",
    "DISC_OUTPUT_SIZE = 16  # Set fixed output size\n",
    "G_face2sketch = Generator(n_residual_blocks=NUM_RESIDUAL_BLOCKS, base_filters=32).to(device)\n",
    "G_sketch2face = Generator(n_residual_blocks=NUM_RESIDUAL_BLOCKS, base_filters=32).to(device)\n",
    "D_face = Discriminator(base_filters=32, output_size=DISC_OUTPUT_SIZE).to(device)\n",
    "D_sketch = Discriminator(base_filters=32, output_size=DISC_OUTPUT_SIZE).to(device)\n",
    "\n",
    "# Print model parameter counts\n",
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "print(f\"Generator parameters: {count_parameters(G_face2sketch):,}\")\n",
    "print(f\"Discriminator parameters: {count_parameters(D_face):,}\")\n",
    "\n",
    "# Initialize weights with normal distribution\n",
    "def weights_init(m):\n",
    "    classname = m.__class__.__name__\n",
    "    if classname.find('Conv') != -1:\n",
    "        nn.init.normal_(m.weight.data, 0.0, 0.02)\n",
    "        if hasattr(m, 'bias') and m.bias is not None:\n",
    "            nn.init.constant_(m.bias.data, 0.0)\n",
    "    elif classname.find('BatchNorm') != -1:\n",
    "        nn.init.normal_(m.weight.data, 1.0, 0.02)\n",
    "        nn.init.constant_(m.bias.data, 0.0)\n",
    "\n",
    "# Apply weight initialization\n",
    "G_face2sketch.apply(weights_init)\n",
    "G_sketch2face.apply(weights_init)\n",
    "D_face.apply(weights_init)\n",
    "D_sketch.apply(weights_init)\n",
    "\n",
    "# ------------------ Loss Functions and Optimizers ------------------\n",
    "\n",
    "# Define loss functions\n",
    "criterion_GAN = nn.MSELoss()  # LSGAN loss\n",
    "criterion_cycle = nn.L1Loss()\n",
    "criterion_identity = nn.L1Loss()\n",
    "\n",
    "# Define optimizers\n",
    "optimizer_G = torch.optim.Adam(\n",
    "    list(G_face2sketch.parameters()) + list(G_sketch2face.parameters()),\n",
    "    lr=LEARNING_RATE,\n",
    "    betas=(BETA1, BETA2)\n",
    ")\n",
    "\n",
    "optimizer_D_face = torch.optim.Adam(\n",
    "    D_face.parameters(),\n",
    "    lr=LEARNING_RATE,\n",
    "    betas=(BETA1, BETA2)\n",
    ")\n",
    "\n",
    "optimizer_D_sketch = torch.optim.Adam(\n",
    "    D_sketch.parameters(),\n",
    "    lr=LEARNING_RATE,\n",
    "    betas=(BETA1, BETA2)\n",
    ")\n",
    "\n",
    "# Learning rate scheduler\n",
    "def lambda_rule(epoch):\n",
    "    return 1.0 - max(0, epoch - 50) / float(50)\n",
    "\n",
    "scheduler_G = torch.optim.lr_scheduler.LambdaLR(optimizer_G, lr_lambda=lambda_rule)\n",
    "scheduler_D_face = torch.optim.lr_scheduler.LambdaLR(optimizer_D_face, lr_lambda=lambda_rule)\n",
    "scheduler_D_sketch = torch.optim.lr_scheduler.LambdaLR(optimizer_D_sketch, lr_lambda=lambda_rule)\n",
    "\n",
    "# ------------------ Helper Functions ------------------\n",
    "\n",
    "# Function to log metrics\n",
    "def log_metrics(epoch, metrics, is_train=True):\n",
    "    mode = 'Train' if is_train else 'Validation'\n",
    "    output = f\"[{mode}] Epoch {epoch+1}/{EPOCHS}\"\n",
    "    for key, value in metrics.items():\n",
    "        output += f\", {key}: {value:.4f}\"\n",
    "    print(output)\n",
    "\n",
    "# Function to save sample images\n",
    "def save_sample_images(epoch, sample_faces, sample_sketches):\n",
    "    with torch.no_grad():\n",
    "        G_face2sketch.eval()\n",
    "        G_sketch2face.eval()\n",
    "        \n",
    "        # Generate fake images\n",
    "        fake_sketches = G_face2sketch(sample_faces)\n",
    "        fake_faces = G_sketch2face(sample_sketches)\n",
    "        \n",
    "        # Generate reconstructed images\n",
    "        reconstructed_faces = G_sketch2face(fake_sketches)\n",
    "        reconstructed_sketches = G_face2sketch(fake_faces)\n",
    "        \n",
    "        # Convert images from [-1, 1] to [0, 1]\n",
    "        sample_faces = (sample_faces + 1) / 2\n",
    "        sample_sketches = (sample_sketches + 1) / 2\n",
    "        fake_faces = (fake_faces + 1) / 2\n",
    "        fake_sketches = (fake_sketches + 1) / 2\n",
    "        reconstructed_faces = (reconstructed_faces + 1) / 2\n",
    "        reconstructed_sketches = (reconstructed_sketches + 1) / 2\n",
    "        \n",
    "        # Create a grid of images\n",
    "        fig, axs = plt.subplots(4, 4, figsize=(20, 20))\n",
    "        \n",
    "        for i in range(min(4, sample_faces.size(0))):\n",
    "            # Original face\n",
    "            axs[i, 0].imshow(sample_faces[i].cpu().permute(1, 2, 0).numpy())\n",
    "            axs[i, 0].set_title('Original Face')\n",
    "            axs[i, 0].axis('off')\n",
    "            \n",
    "            # Fake sketch\n",
    "            axs[i, 1].imshow(fake_sketches[i].cpu().permute(1, 2, 0).numpy())\n",
    "            axs[i, 1].set_title('Generated Sketch')\n",
    "            axs[i, 1].axis('off')\n",
    "            \n",
    "            # Original sketch\n",
    "            axs[i, 2].imshow(sample_sketches[i].cpu().permute(1, 2, 0).numpy())\n",
    "            axs[i, 2].set_title('Original Sketch')\n",
    "            axs[i, 2].axis('off')\n",
    "            \n",
    "            # Fake face\n",
    "            axs[i, 3].imshow(fake_faces[i].cpu().permute(1, 2, 0).numpy())\n",
    "            axs[i, 3].set_title('Generated Face')\n",
    "            axs[i, 3].axis('off')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.savefig(os.path.join(RESULT_DIR, f'sample_epoch_{epoch+1}.png'))\n",
    "        plt.close()\n",
    "        \n",
    "        G_face2sketch.train()\n",
    "        G_sketch2face.train()\n",
    "\n",
    "# Function to save model checkpoints\n",
    "def save_checkpoint(epoch, G_face2sketch, G_sketch2face, D_face, D_sketch, \n",
    "                    optimizer_G, optimizer_D_face, optimizer_D_sketch,\n",
    "                    scheduler_G, scheduler_D_face, scheduler_D_sketch, metrics):\n",
    "    torch.save({\n",
    "        'epoch': epoch,\n",
    "        'G_face2sketch_state_dict': G_face2sketch.state_dict(),\n",
    "        'G_sketch2face_state_dict': G_sketch2face.state_dict(),\n",
    "        'D_face_state_dict': D_face.state_dict(),\n",
    "        'D_sketch_state_dict': D_sketch.state_dict(),\n",
    "        'optimizer_G_state_dict': optimizer_G.state_dict(),\n",
    "        'optimizer_D_face_state_dict': optimizer_D_face.state_dict(),\n",
    "        'optimizer_D_sketch_state_dict': optimizer_D_sketch.state_dict(),\n",
    "        'scheduler_G_state_dict': scheduler_G.state_dict(),\n",
    "        'scheduler_D_face_state_dict': scheduler_D_face.state_dict(),\n",
    "        'scheduler_D_sketch_state_dict': scheduler_D_sketch.state_dict(),\n",
    "        'metrics': metrics\n",
    "    }, os.path.join(CHECKPOINT_DIR, f'checkpoint_epoch_{epoch+1}.pth'))\n",
    "    \n",
    "    # Save latest checkpoint for easier resuming\n",
    "    torch.save({\n",
    "        'epoch': epoch,\n",
    "        'G_face2sketch_state_dict': G_face2sketch.state_dict(),\n",
    "        'G_sketch2face_state_dict': G_sketch2face.state_dict(),\n",
    "        'D_face_state_dict': D_face.state_dict(),\n",
    "        'D_sketch_state_dict': D_sketch.state_dict(),\n",
    "        'optimizer_G_state_dict': optimizer_G.state_dict(),\n",
    "        'optimizer_D_face_state_dict': optimizer_D_face.state_dict(),\n",
    "        'optimizer_D_sketch_state_dict': optimizer_D_sketch.state_dict(),\n",
    "        'scheduler_G_state_dict': scheduler_G.state_dict(),\n",
    "        'scheduler_D_face_state_dict': scheduler_D_face.state_dict(),\n",
    "        'scheduler_D_sketch_state_dict': scheduler_D_sketch.state_dict(),\n",
    "        'metrics': metrics\n",
    "    }, os.path.join(CHECKPOINT_DIR, 'latest_checkpoint.pth'))\n",
    "\n",
    "# Function to load model checkpoints\n",
    "def load_checkpoint(checkpoint_path, G_face2sketch, G_sketch2face, D_face, D_sketch, \n",
    "                   optimizer_G, optimizer_D_face, optimizer_D_sketch,\n",
    "                   scheduler_G, scheduler_D_face, scheduler_D_sketch):\n",
    "    checkpoint = torch.load(checkpoint_path, map_location=device)\n",
    "    \n",
    "    G_face2sketch.load_state_dict(checkpoint['G_face2sketch_state_dict'])\n",
    "    G_sketch2face.load_state_dict(checkpoint['G_sketch2face_state_dict'])\n",
    "    D_face.load_state_dict(checkpoint['D_face_state_dict'])\n",
    "    D_sketch.load_state_dict(checkpoint['D_sketch_state_dict'])\n",
    "    \n",
    "    optimizer_G.load_state_dict(checkpoint['optimizer_G_state_dict'])\n",
    "    optimizer_D_face.load_state_dict(checkpoint['optimizer_D_face_state_dict'])\n",
    "    optimizer_D_sketch.load_state_dict(checkpoint['optimizer_D_sketch_state_dict'])\n",
    "    \n",
    "    scheduler_G.load_state_dict(checkpoint['scheduler_G_state_dict'])\n",
    "    scheduler_D_face.load_state_dict(checkpoint['scheduler_D_face_state_dict'])\n",
    "    scheduler_D_sketch.load_state_dict(checkpoint['scheduler_D_sketch_state_dict'])\n",
    "    \n",
    "    epoch = checkpoint['epoch']\n",
    "    metrics = checkpoint['metrics']\n",
    "    \n",
    "    return epoch, metrics\n",
    "\n",
    "# Image buffer to stabilize training\n",
    "class ImageBuffer:\n",
    "    def __init__(self, max_size=50):\n",
    "        self.max_size = max_size\n",
    "        self.data = []\n",
    "    \n",
    "    def push_and_pop(self, images):\n",
    "        result = []\n",
    "        for image in images:\n",
    "            image = image.unsqueeze(0)  # Add batch dimension\n",
    "            if len(self.data) < self.max_size:\n",
    "                self.data.append(image)\n",
    "                result.append(image)\n",
    "            else:\n",
    "                if np.random.uniform(0, 1) > 0.5:\n",
    "                    i = np.random.randint(0, self.max_size)\n",
    "                    temp = self.data[i].clone()\n",
    "                    self.data[i] = image\n",
    "                    result.append(temp)\n",
    "                else:\n",
    "                    result.append(image)\n",
    "        return torch.cat(result, 0)\n",
    "\n",
    "# Create image buffers\n",
    "fake_face_buffer = ImageBuffer(max_size=20)  # Reduced buffer size\n",
    "fake_sketch_buffer = ImageBuffer(max_size=20)  # Reduced buffer size\n",
    "\n",
    "# ------------------ Training Function ------------------\n",
    "\n",
    "def train():\n",
    "    # Initialize metrics tracking\n",
    "    all_metrics = {\n",
    "        'train': {\n",
    "            'D_face_loss': [], 'D_sketch_loss': [], \n",
    "            'G_face2sketch_loss': [], 'G_sketch2face_loss': [],\n",
    "            'cycle_loss': [], 'identity_loss': [], 'total_G_loss': []\n",
    "        },\n",
    "        'val': {\n",
    "            'D_face_loss': [], 'D_sketch_loss': [], \n",
    "            'G_face2sketch_loss': [], 'G_sketch2face_loss': [],\n",
    "            'cycle_loss': [], 'identity_loss': [], 'total_G_loss': []\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    # Get a sample batch for generating images during training\n",
    "    sample_batch = next(iter(val_dataloader))\n",
    "    sample_faces = sample_batch['face'][:1].to(device)  # Limited to 1 sample to save memory\n",
    "    sample_sketches = sample_batch['sketch'][:1].to(device)\n",
    "    \n",
    "    # Start training\n",
    "    start_epoch = 0\n",
    "    \n",
    "    # Check if we have checkpoints to resume from\n",
    "    checkpoint_path = os.path.join(CHECKPOINT_DIR, 'latest_checkpoint.pth')\n",
    "    if os.path.exists(checkpoint_path):\n",
    "        print(f\"Resuming from checkpoint: {checkpoint_path}\")\n",
    "        try:\n",
    "            start_epoch, resuming_metrics = load_checkpoint(\n",
    "                checkpoint_path, G_face2sketch, G_sketch2face, D_face, D_sketch,\n",
    "                optimizer_G, optimizer_D_face, optimizer_D_sketch,\n",
    "                scheduler_G, scheduler_D_face, scheduler_D_sketch\n",
    "            )\n",
    "            all_metrics = resuming_metrics\n",
    "            start_epoch += 1  # Start from the next epoch\n",
    "            print(f\"Successfully resumed from epoch {start_epoch}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading checkpoint: {e}\")\n",
    "            print(\"Starting from scratch\")\n",
    "            start_epoch = 0\n",
    "    \n",
    "    for epoch in range(start_epoch, EPOCHS):\n",
    "        # Clear CUDA cache between epochs\n",
    "        if torch.cuda.is_available():\n",
    "            torch.cuda.empty_cache()\n",
    "            \n",
    "        # Training phase\n",
    "        G_face2sketch.train()\n",
    "        G_sketch2face.train()\n",
    "        D_face.train()\n",
    "        D_sketch.train()\n",
    "        \n",
    "        # Metrics for this epoch\n",
    "        epoch_metrics = {\n",
    "            'D_face_loss': 0.0,\n",
    "            'D_sketch_loss': 0.0,\n",
    "            'G_face2sketch_loss': 0.0,\n",
    "            'G_sketch2face_loss': 0.0,\n",
    "            'cycle_loss': 0.0,\n",
    "            'identity_loss': 0.0,\n",
    "            'total_G_loss': 0.0\n",
    "        }\n",
    "        \n",
    "        start_time = time.time()\n",
    "        \n",
    "        for batch_idx, batch in enumerate(train_dataloader):\n",
    "            # Load batch data\n",
    "            real_faces = batch['face'].to(device)\n",
    "            real_sketches = batch['sketch'].to(device)\n",
    "            batch_size = real_faces.size(0)\n",
    "            \n",
    "            # Skip bad batches\n",
    "            if real_faces.size(0) == 0 or real_sketches.size(0) == 0:\n",
    "                print(f\"Skipping empty batch {batch_idx}\")\n",
    "                continue\n",
    "                \n",
    "            try:\n",
    "                # FIX: Create ground truth tensors with consistent size\n",
    "                valid = torch.ones((batch_size, 1, DISC_OUTPUT_SIZE, DISC_OUTPUT_SIZE), requires_grad=False).to(device)\n",
    "                fake = torch.zeros((batch_size, 1, DISC_OUTPUT_SIZE, DISC_OUTPUT_SIZE), requires_grad=False).to(device)\n",
    "                \n",
    "                #------------------------\n",
    "                # Train Generators\n",
    "                #------------------------\n",
    "                optimizer_G.zero_grad()\n",
    "                \n",
    "                # Identity loss\n",
    "                identity_sketch = G_sketch2face(real_sketches)\n",
    "                identity_face = G_face2sketch(real_faces)\n",
    "                loss_identity_sketch = criterion_identity(identity_sketch, real_sketches)\n",
    "                loss_identity_face = criterion_identity(identity_face, real_faces)\n",
    "                loss_identity = (loss_identity_sketch + loss_identity_face) * LAMBDA_IDENTITY\n",
    "                \n",
    "                # Free up memory\n",
    "                del identity_sketch, identity_face\n",
    "                if torch.cuda.is_available():\n",
    "                    torch.cuda.empty_cache()\n",
    "                \n",
    "                # GAN loss\n",
    "                fake_sketches = G_face2sketch(real_faces)\n",
    "                loss_GAN_face2sketch = criterion_GAN(D_sketch(fake_sketches), valid)\n",
    "                \n",
    "                fake_faces = G_sketch2face(real_sketches)\n",
    "                loss_GAN_sketch2face = criterion_GAN(D_face(fake_faces), valid)\n",
    "                \n",
    "                # Cycle consistency loss\n",
    "                reconstructed_faces = G_sketch2face(fake_sketches)\n",
    "                loss_cycle_face = criterion_cycle(reconstructed_faces, real_faces) * LAMBDA_CYCLE\n",
    "                \n",
    "                reconstructed_sketches = G_face2sketch(fake_faces)\n",
    "                loss_cycle_sketch = criterion_cycle(reconstructed_sketches, real_sketches) * LAMBDA_CYCLE\n",
    "                \n",
    "                # Total generator loss\n",
    "                loss_G = loss_GAN_face2sketch + loss_GAN_sketch2face + loss_cycle_face + loss_cycle_sketch + loss_identity\n",
    "                \n",
    "                # Free up memory for gradients\n",
    "                del reconstructed_faces, reconstructed_sketches\n",
    "                if torch.cuda.is_available():\n",
    "                    torch.cuda.empty_cache()\n",
    "                \n",
    "                loss_G.backward()\n",
    "                optimizer_G.step()\n",
    "                \n",
    "                # Free up tensors\n",
    "                g_loss_val = loss_G.item()\n",
    "                identity_loss_val = loss_identity.item()\n",
    "                cycle_face_loss_val = loss_cycle_face.item()\n",
    "                cycle_sketch_loss_val = loss_cycle_sketch.item()\n",
    "                gan_face2sketch_loss_val = loss_GAN_face2sketch.item()\n",
    "                gan_sketch2face_loss_val = loss_GAN_sketch2face.item()\n",
    "                \n",
    "                del loss_G, loss_identity, loss_cycle_face, loss_cycle_sketch\n",
    "                del loss_GAN_face2sketch, loss_GAN_sketch2face\n",
    "                if torch.cuda.is_available():\n",
    "                    torch.cuda.empty_cache()\n",
    "                \n",
    "                #------------------------\n",
    "                # Train Discriminators\n",
    "                #------------------------\n",
    "                \n",
    "                # Discriminator Face\n",
    "                optimizer_D_face.zero_grad()\n",
    "                \n",
    "                # Real loss\n",
    "                loss_real_face = criterion_GAN(D_face(real_faces), valid)\n",
    "                \n",
    "                # Fake loss (using buffer)\n",
    "                fake_faces_detached = fake_faces.detach()  # Detach to avoid computing gradients through generator\n",
    "                fake_faces_ = fake_face_buffer.push_and_pop(fake_faces_detached)\n",
    "                loss_fake_face = criterion_GAN(D_face(fake_faces_), fake)\n",
    "                \n",
    "                # Total discriminator face loss\n",
    "                loss_D_face = (loss_real_face + loss_fake_face) * 0.5\n",
    "                loss_D_face.backward()\n",
    "                optimizer_D_face.step()\n",
    "                \n",
    "                # Free up tensors\n",
    "                d_face_loss_val = loss_D_face.item()\n",
    "                del loss_real_face, loss_fake_face, fake_faces_detached, fake_faces_\n",
    "                if torch.cuda.is_available():\n",
    "                    torch.cuda.empty_cache()\n",
    "                \n",
    "                # Discriminator Sketch\n",
    "                optimizer_D_sketch.zero_grad()\n",
    "                \n",
    "                # Real loss\n",
    "                loss_real_sketch = criterion_GAN(D_sketch(real_sketches), valid)\n",
    "                \n",
    "                # Fake loss (using buffer)\n",
    "                fake_sketches_detached = fake_sketches.detach()\n",
    "                fake_sketches_ = fake_sketch_buffer.push_and_pop(fake_sketches_detached)\n",
    "                loss_fake_sketch = criterion_GAN(D_sketch(fake_sketches_), fake)\n",
    "                \n",
    "                # Total discriminator sketch loss\n",
    "                loss_D_sketch = (loss_real_sketch + loss_fake_sketch) * 0.5\n",
    "                loss_D_sketch.backward()\n",
    "                optimizer_D_sketch.step()\n",
    "                \n",
    "                # Free up remaining tensors\n",
    "                d_sketch_loss_val = loss_D_sketch.item()\n",
    "                del loss_real_sketch, loss_fake_sketch, fake_sketches_detached, fake_sketches_\n",
    "                if torch.cuda.is_available():\n",
    "                    torch.cuda.empty_cache()\n",
    "                \n",
    "                # Update metrics\n",
    "                epoch_metrics['D_face_loss'] += d_face_loss_val\n",
    "                epoch_metrics['D_sketch_loss'] += d_sketch_loss_val\n",
    "                epoch_metrics['G_face2sketch_loss'] += gan_face2sketch_loss_val\n",
    "                epoch_metrics['G_sketch2face_loss'] += gan_sketch2face_loss_val\n",
    "                epoch_metrics['cycle_loss'] += (cycle_face_loss_val + cycle_sketch_loss_val)\n",
    "                epoch_metrics['identity_loss'] += identity_loss_val\n",
    "                epoch_metrics['total_G_loss'] += g_loss_val\n",
    "                \n",
    "                # Free up any remaining large tensors\n",
    "                del fake_faces, fake_sketches\n",
    "                if torch.cuda.is_available():\n",
    "                    torch.cuda.empty_cache()\n",
    "                \n",
    "                # Print progress\n",
    "                if (batch_idx + 1) % 10 == 0 or batch_idx == len(train_dataloader) - 1:\n",
    "                    print(f\"[Train] Epoch {epoch+1}/{EPOCHS} - Batch {batch_idx+1}/{len(train_dataloader)}, \"\n",
    "                          f\"D_face: {d_face_loss_val:.4f}, D_sketch: {d_sketch_loss_val:.4f}, \"\n",
    "                          f\"G: {g_loss_val:.4f}, Cycle: {(cycle_face_loss_val + cycle_sketch_loss_val):.4f}, \"\n",
    "                          f\"Identity: {identity_loss_val:.4f}\")\n",
    "                    \n",
    "                # Every 50 batches, run garbage collection\n",
    "                if batch_idx % 50 == 0:\n",
    "                    gc.collect()\n",
    "                    if torch.cuda.is_available():\n",
    "                        torch.cuda.empty_cache()\n",
    "                        \n",
    "            except RuntimeError as e:\n",
    "                if 'out of memory' in str(e):\n",
    "                    print(f\"WARNING: Out of memory in batch {batch_idx}\")\n",
    "                    if torch.cuda.is_available():\n",
    "                        torch.cuda.empty_cache()\n",
    "                    continue\n",
    "                else:\n",
    "                    print(f\"Error details: {e}\")\n",
    "                    raise e\n",
    "        \n",
    "        # Calculate average metrics for the epoch\n",
    "        for key in epoch_metrics:\n",
    "            if len(train_dataloader) > 0:\n",
    "                epoch_metrics[key] /= len(train_dataloader)\n",
    "            all_metrics['train'][key].append(epoch_metrics[key])\n",
    "        \n",
    "        # Log training metrics\n",
    "        log_metrics(epoch, epoch_metrics, is_train=True)\n",
    "        \n",
    "        #------------------------\n",
    "        # Validation phase\n",
    "        #------------------------\n",
    "        G_face2sketch.eval()\n",
    "        G_sketch2face.eval()\n",
    "        D_face.eval()\n",
    "        D_sketch.eval()\n",
    "        \n",
    "        # Metrics for validation\n",
    "        val_metrics = {\n",
    "            'D_face_loss': 0.0,\n",
    "            'D_sketch_loss': 0.0,\n",
    "            'G_face2sketch_loss': 0.0,\n",
    "            'G_sketch2face_loss': 0.0,\n",
    "            'cycle_loss': 0.0,\n",
    "            'identity_loss': 0.0,\n",
    "            'total_G_loss': 0.0\n",
    "        }\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for batch_idx, batch in enumerate(val_dataloader):\n",
    "                try:\n",
    "                    # Load batch data\n",
    "                    real_faces = batch['face'].to(device)\n",
    "                    real_sketches = batch['sketch'].to(device)\n",
    "                    batch_size = real_faces.size(0)\n",
    "                    \n",
    "                    # Skip bad batches\n",
    "                    if real_faces.size(0) == 0 or real_sketches.size(0) == 0:\n",
    "                        continue\n",
    "                    \n",
    "                    # FIX: Create ground truth tensors with consistent size\n",
    "                    valid = torch.ones((batch_size, 1, DISC_OUTPUT_SIZE, DISC_OUTPUT_SIZE), requires_grad=False).to(device)\n",
    "                    fake = torch.zeros((batch_size, 1, DISC_OUTPUT_SIZE, DISC_OUTPUT_SIZE), requires_grad=False).to(device)\n",
    "                    \n",
    "                    # Identity loss\n",
    "                    identity_sketch = G_sketch2face(real_sketches)\n",
    "                    identity_face = G_face2sketch(real_faces)\n",
    "                    loss_identity_sketch = criterion_identity(identity_sketch, real_sketches)\n",
    "                    loss_identity_face = criterion_identity(identity_face, real_faces)\n",
    "                    loss_identity = (loss_identity_sketch + loss_identity_face) * LAMBDA_IDENTITY\n",
    "                    \n",
    "                    # GAN loss\n",
    "                    fake_sketches = G_face2sketch(real_faces)\n",
    "                    loss_GAN_face2sketch = criterion_GAN(D_sketch(fake_sketches), valid)\n",
    "                    \n",
    "                    fake_faces = G_sketch2face(real_sketches)\n",
    "                    loss_GAN_sketch2face = criterion_GAN(D_face(fake_faces), valid)\n",
    "                    \n",
    "                    # Cycle consistency loss\n",
    "                    reconstructed_faces = G_sketch2face(fake_sketches)\n",
    "                    loss_cycle_face = criterion_cycle(reconstructed_faces, real_faces) * LAMBDA_CYCLE\n",
    "                    \n",
    "                    reconstructed_sketches = G_face2sketch(fake_faces)\n",
    "                    loss_cycle_sketch = criterion_cycle(reconstructed_sketches, real_sketches) * LAMBDA_CYCLE\n",
    "                    \n",
    "                    # Total generator loss\n",
    "                    loss_G = loss_GAN_face2sketch + loss_GAN_sketch2face + loss_cycle_face + loss_cycle_sketch + loss_identity\n",
    "                    \n",
    "                    # Discriminator Face\n",
    "                    loss_real_face = criterion_GAN(D_face(real_faces), valid)\n",
    "                    loss_fake_face = criterion_GAN(D_face(fake_faces), fake)\n",
    "                    loss_D_face = (loss_real_face + loss_fake_face) * 0.5\n",
    "                    \n",
    "                    # Discriminator Sketch\n",
    "                    loss_real_sketch = criterion_GAN(D_sketch(real_sketches), valid)\n",
    "                    loss_fake_sketch = criterion_GAN(D_sketch(fake_sketches), fake)\n",
    "                    loss_D_sketch = (loss_real_sketch + loss_fake_sketch) * 0.5\n",
    "                    \n",
    "                    # Update metrics\n",
    "                    val_metrics['D_face_loss'] += loss_D_face.item()\n",
    "                    val_metrics['D_sketch_loss'] += loss_D_sketch.item()\n",
    "                    val_metrics['G_face2sketch_loss'] += loss_GAN_face2sketch.item()\n",
    "                    val_metrics['G_sketch2face_loss'] += loss_GAN_sketch2face.item()\n",
    "                    val_metrics['cycle_loss'] += (loss_cycle_face.item() + loss_cycle_sketch.item())\n",
    "                    val_metrics['identity_loss'] += loss_identity.item()\n",
    "                    val_metrics['total_G_loss'] += loss_G.item()\n",
    "                    \n",
    "                except RuntimeError as e:\n",
    "                    if 'out of memory' in str(e):\n",
    "                        print(f\"WARNING: Out of memory in validation batch {batch_idx}\")\n",
    "                        if torch.cuda.is_available():\n",
    "                            torch.cuda.empty_cache()\n",
    "                        continue\n",
    "                    else:\n",
    "                        print(f\"Error details: {e}\")\n",
    "                        raise e\n",
    "        \n",
    "        # Calculate average metrics for validation\n",
    "        for key in val_metrics:\n",
    "            if len(val_dataloader) > 0:\n",
    "                val_metrics[key] /= len(val_dataloader)\n",
    "            all_metrics['val'][key].append(val_metrics[key])\n",
    "        \n",
    "        # Log validation metrics\n",
    "        log_metrics(epoch, val_metrics, is_train=False)\n",
    "        \n",
    "        # Update learning rates\n",
    "        scheduler_G.step()\n",
    "        scheduler_D_face.step()\n",
    "        scheduler_D_sketch.step()\n",
    "        \n",
    "        # Save sample images every 5 epochs\n",
    "        if (epoch + 1) % 5 == 0 or epoch == 0:\n",
    "            save_sample_images(epoch, sample_faces, sample_sketches)\n",
    "        \n",
    "        # Save checkpoint\n",
    "        save_checkpoint(\n",
    "            epoch, G_face2sketch, G_sketch2face, D_face, D_sketch,\n",
    "            optimizer_G, optimizer_D_face, optimizer_D_sketch,\n",
    "            scheduler_G, scheduler_D_face, scheduler_D_sketch,\n",
    "            all_metrics\n",
    "        )\n",
    "        \n",
    "        # Save metrics to CSV\n",
    "        metrics_df = pd.DataFrame({\n",
    "            'epoch': range(1, epoch + 2),\n",
    "            'train_D_face_loss': all_metrics['train']['D_face_loss'],\n",
    "            'train_D_sketch_loss': all_metrics['train']['D_sketch_loss'],\n",
    "            'train_G_face2sketch_loss': all_metrics['train']['G_face2sketch_loss'],\n",
    "            'train_G_sketch2face_loss': all_metrics['train']['G_sketch2face_loss'],\n",
    "            'train_cycle_loss': all_metrics['train']['cycle_loss'],\n",
    "            'train_identity_loss': all_metrics['train']['identity_loss'],\n",
    "            'train_total_G_loss': all_metrics['train']['total_G_loss'],\n",
    "            'val_D_face_loss': all_metrics['val']['D_face_loss'],\n",
    "            'val_D_sketch_loss': all_metrics['val']['D_sketch_loss'],\n",
    "            'val_G_face2sketch_loss': all_metrics['val']['G_face2sketch_loss'],\n",
    "            'val_G_sketch2face_loss': all_metrics['val']['G_sketch2face_loss'],\n",
    "            'val_cycle_loss': all_metrics['val']['cycle_loss'],\n",
    "            'val_identity_loss': all_metrics['val']['identity_loss'],\n",
    "            'val_total_G_loss': all_metrics['val']['total_G_loss']\n",
    "        })\n",
    "        metrics_df.to_csv(os.path.join(RESULT_DIR, 'metrics.csv'), index=False)\n",
    "        \n",
    "        # Calculate time elapsed for the epoch\n",
    "        epoch_time = time.time() - start_time\n",
    "        print(f\"Epoch {epoch+1} completed in {epoch_time:.2f} seconds\")\n",
    "        \n",
    "        # Run memory cleanup between epochs\n",
    "        gc.collect()\n",
    "        if torch.cuda.is_available():\n",
    "            torch.cuda.empty_cache()\n",
    "    \n",
    "    return all_metrics\n",
    "\n",
    "# ------------------ Test Function ------------------\n",
    "\n",
    "def test_model(num_samples=5):\n",
    "    # Create a directory for test results\n",
    "    test_results_dir = os.path.join(RESULT_DIR, 'test_results')\n",
    "    os.makedirs(test_results_dir, exist_ok=True)\n",
    "    \n",
    "    G_face2sketch.eval()\n",
    "    G_sketch2face.eval()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for i, batch in enumerate(val_dataloader):\n",
    "            if i >= num_samples:\n",
    "                break\n",
    "                \n",
    "            # Process face to sketch\n",
    "            real_face = batch['face'].to(device)\n",
    "            fake_sketch = G_face2sketch(real_face)\n",
    "            reconstructed_face = G_sketch2face(fake_sketch)\n",
    "            \n",
    "            # Process sketch to face\n",
    "            real_sketch = batch['sketch'].to(device)\n",
    "            fake_face = G_sketch2face(real_sketch)\n",
    "            reconstructed_sketch = G_face2sketch(fake_face)\n",
    "            \n",
    "            # Convert images from [-1, 1] to [0, 1]\n",
    "            real_face = (real_face + 1) / 2\n",
    "            fake_sketch = (fake_sketch + 1) / 2\n",
    "            reconstructed_face = (reconstructed_face + 1) / 2\n",
    "            real_sketch = (real_sketch + 1) / 2\n",
    "            fake_face = (fake_face + 1) / 2\n",
    "            reconstructed_sketch = (reconstructed_sketch + 1) / 2\n",
    "            \n",
    "            # Save face to sketch results\n",
    "            fig, axs = plt.subplots(1, 3, figsize=(15, 5))\n",
    "            axs[0].imshow(real_face[0].cpu().permute(1, 2, 0).numpy())\n",
    "            axs[0].set_title('Original Face')\n",
    "            axs[0].axis('off')\n",
    "            \n",
    "            axs[1].imshow(fake_sketch[0].cpu().permute(1, 2, 0).numpy())\n",
    "            axs[1].set_title('Generated Sketch')\n",
    "            axs[1].axis('off')\n",
    "            \n",
    "            axs[2].imshow(reconstructed_face[0].cpu().permute(1, 2, 0).numpy())\n",
    "            axs[2].set_title('Reconstructed Face')\n",
    "            axs[2].axis('off')\n",
    "            \n",
    "            plt.tight_layout()\n",
    "            plt.savefig(os.path.join(test_results_dir, f'face2sketch_test_{i+1}.png'))\n",
    "            plt.close()\n",
    "            \n",
    "            # Save sketch to face results\n",
    "            fig, axs = plt.subplots(1, 3, figsize=(15, 5))\n",
    "            axs[0].imshow(real_sketch[0].cpu().permute(1, 2, 0).numpy())\n",
    "            axs[0].set_title('Original Sketch')\n",
    "            axs[0].axis('off')\n",
    "            \n",
    "            axs[1].imshow(fake_face[0].cpu().permute(1, 2, 0).numpy())\n",
    "            axs[1].set_title('Generated Face')\n",
    "            axs[1].axis('off')\n",
    "            \n",
    "            axs[2].imshow(reconstructed_sketch[0].cpu().permute(1, 2, 0).numpy())\n",
    "            axs[2].set_title('Reconstructed Sketch')\n",
    "            axs[2].axis('off')\n",
    "            \n",
    "            plt.tight_layout()\n",
    "            plt.savefig(os.path.join(test_results_dir, f'sketch2face_test_{i+1}.png'))\n",
    "            plt.close()\n",
    "            \n",
    "            # Free memory\n",
    "            del real_face, fake_sketch, reconstructed_face, real_sketch, fake_face, reconstructed_sketch\n",
    "            if torch.cuda.is_available():\n",
    "                torch.cuda.empty_cache()\n",
    "\n",
    "# ------------------ Main Execution ------------------\n",
    "\n",
    "# Main function to run training and testing\n",
    "def main():\n",
    "    print(\"Starting CycleGAN training...\")\n",
    "    try:\n",
    "        # Train the model\n",
    "        train_metrics = train()\n",
    "        \n",
    "        # Test the model\n",
    "        print(\"Testing the model...\")\n",
    "        test_model(num_samples=5)\n",
    "        \n",
    "        print(\"Training and testing completed successfully!\")\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {str(e)}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "\n",
    "# Run the main function\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "230d1487",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-12T08:54:38.449987Z",
     "iopub.status.busy": "2025-04-12T08:54:38.449749Z",
     "iopub.status.idle": "2025-04-12T08:55:45.409345Z",
     "shell.execute_reply": "2025-04-12T08:55:45.408628Z"
    },
    "papermill": {
     "duration": 67.047756,
     "end_time": "2025-04-12T08:55:45.476621",
     "exception": false,
     "start_time": "2025-04-12T08:54:38.428865",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created zip file at /kaggle/working/all_results.zip\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<a href='/kaggle/working/all_results.zip' target='_blank'>/kaggle/working/all_results.zip</a><br>"
      ],
      "text/plain": [
       "/kaggle/working/all_results.zip"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "import os\n",
    "import zipfile\n",
    "from IPython.display import display, FileLink\n",
    "\n",
    "# Define the directory to zip\n",
    "directory_to_zip = '/kaggle/working/'\n",
    "\n",
    "# Define output zip file path\n",
    "output_path = '/kaggle/working/all_results.zip'\n",
    "\n",
    "# Create a function to zip the directory\n",
    "def zip_directory(directory, zipname):\n",
    "    with zipfile.ZipFile(zipname, 'w', zipfile.ZIP_DEFLATED) as zipf:\n",
    "        # Iterate through all files and subdirectories\n",
    "        for root, dirs, files in os.walk(directory):\n",
    "            for file in files:\n",
    "                # Skip the zip file itself to avoid recursion\n",
    "                if file == os.path.basename(zipname):\n",
    "                    continue\n",
    "                \n",
    "                # Get the full file path\n",
    "                file_path = os.path.join(root, file)\n",
    "                \n",
    "                # Calculate the relative path for the file in the zip\n",
    "                relative_path = os.path.relpath(file_path, directory)\n",
    "                \n",
    "                # Add the file to the zip\n",
    "                zipf.write(file_path, relative_path)\n",
    "        \n",
    "        print(f\"Created zip file at {zipname}\")\n",
    "        \n",
    "# Zip the directory\n",
    "zip_directory(directory_to_zip, output_path)\n",
    "\n",
    "# Create a download link for the zip file\n",
    "display(FileLink(output_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ce9d255",
   "metadata": {
    "papermill": {
     "duration": 0.021042,
     "end_time": "2025-04-12T08:55:45.518218",
     "exception": false,
     "start_time": "2025-04-12T08:55:45.497176",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "databundleVersionId": 3778506,
     "datasetId": 2151228,
     "sourceId": 3724153,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31011,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 635.62162,
   "end_time": "2025-04-12T08:55:48.390662",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-04-12T08:45:12.769042",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
